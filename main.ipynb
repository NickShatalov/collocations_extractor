{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Курсовая работа\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "import ngrammer\n",
    "\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pickle as pkl\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNTAXNET_INPUT = \"sentences.txt\"\n",
    "SYNTAXNET_OUTPUT = \"syntaxnet_out.txt\"\n",
    "\n",
    "LEMMATIZED_COLLECTION = \"../lemmatized_collection/\"\n",
    "STOPWORDS_FILE = \"../stopwords.txt\"\n",
    "NGRAMMS_FILE = \"../ngramms.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataset_collect'></a>\n",
    "# Сборка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIKI_XML = \"./Data/Input/wiki.xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='collocations_collect'></a>\n",
    "## Коллокации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLOCS_FILE = \"./Data/Input/gt_collocs.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting collocations from hyperlinks...\n",
      "Done!\n",
      "\n",
      "Stats:\n",
      "hyperlinks:\t9200\n",
      "filtered hl:\t11375\n",
      "collocations:\t3651\n"
     ]
    }
   ],
   "source": [
    "! python extract_collocations.py {WIKI_XML} -o {COLLOCS_FILE} --min 2 --max 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(COLLOCS_FILE, \"r\") as f:\n",
    "    collocs = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['computer scientist',\n",
       " 'mikhail moiseevich bongard',\n",
       " 'pattern recognition',\n",
       " 'gdel escher bach',\n",
       " 'douglas hofstadter']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collocs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='documents_collect'></a>\n",
    "## Документы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Документы получаем с помощью [wikiextractor](https://github.com/attardi/wikiextractor)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_FOLDER = \"./Data/Input/collection/\"\n",
    "WIKIEXTRACTOR = \"./wikiextractor/WikiExtractor.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting texts...\n",
      "WARNING: Template errors in article 'Structured sparsity regularization' (48844125): title(1) recursion(0, 0, 0)\n",
      "Done!\n",
      "\n",
      "Stats:\n",
      "documents:\t198\n"
     ]
    }
   ],
   "source": [
    "! python extract_documents.py {WIKI_XML} -o {COLLECTION_FOLDER} --wikiextractor {WIKIEXTRACTOR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='syntaxnet'></a>\n",
    "# SyntaxNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='syntaxnet_run'></a>\n",
    "## Запуск SyntaxNet\n",
    "docker взял [здесь](https://hub.docker.com/r/inemo/syntaxnet_eng/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNTAXNET_OUTPUT = \"./Data/Component_Results/syntaxnet/syntaxnet_out.txt\"\n",
    "SYNTAXNET_RESULT = \"./Data/Component_Results/syntaxnet/results.csv\"\n",
    "LEMMATIZED_COLLECTION = \"./Data/Component_Results/syntaxnet/lemmatized_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing documents...\n",
      "We already have syntaxnet output\n",
      "Postprocessing syntaxnet results...\n",
      "Saving syntaxnet output\n",
      "Saving lemmatized collection...\n",
      "Done!\n",
      "\n",
      "Stats:\n",
      "sentences:\t7704\n"
     ]
    }
   ],
   "source": [
    "cmd = ' '.join(['python', 'run_syntaxnet.py', COLLECTION_FOLDER,\n",
    "#                 '-o', SYNTAXNET_RESULT,\n",
    "                '--syntaxnet_ready', SYNTAXNET_OUTPUT,\n",
    "                '--lemmatize', LEMMATIZED_COLLECTION,\n",
    "                '--syntaxnet_out', SYNTAXNET_OUTPUT])\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='topmine'></a>\n",
    "# TopMine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLOCS_TOPMINE = \"./Data/Output/topmine_collocs.txt\"\n",
    "TOPMINE_OUTPUT = \"./Data/Component_Results/topmine/topmine.csv\"\n",
    "STOPWORDS_FILE = \"./Data/Input/stopwords.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running TopMine...\n",
      "Collecting features...\n",
      "Done!\n",
      "\n",
      "Stats:\n",
      "stopwords:\t\t\t175\n",
      "ngramms with features:\t\t29722\n",
      "extracted unique ngramms:\t5179\n"
     ]
    }
   ],
   "source": [
    "cmd = ' '.join(['python', 'run_topmine.py', LEMMATIZED_COLLECTION,\n",
    "                '-o', TOPMINE_OUTPUT,\n",
    "                '--collocations_output', COLLOCS_TOPMINE,\n",
    "                '--stopwords', STOPWORDS_FILE,\n",
    "                '--threshold', '1.2']) # 1.8\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"syntaxnet_postprocess\"></a>\n",
    "## Обработка результатов SyntaxNet'а"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNTAXNET_DISTANCES = \"./Data/Component_Results/syntaxnet/syntaxnet.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Syntaxnet output...\n",
      "100%|██████████████████████████████████████▉| 7699/7704 [40:02<00:01,  3.20it/s]\n"
     ]
    }
   ],
   "source": [
    "cmd = ' '.join(['python', 'process_syntaxnet.py', SYNTAXNET_OUTPUT,\n",
    "                '-o', SYNTAXNET_DISTANCES,\n",
    "                '--lemmatized_collection', LEMMATIZED_COLLECTION,\n",
    "                '--topmine_data', TOPMINE_OUTPUT])\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/Output/topmine_collocs.txt', 'r') as f:\n",
    "    topmine_collocs = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "collocs = sorted(collocs)\n",
    "topmine_collocs = sorted(topmine_collocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatized_collocs = []\n",
    "for colloc in collocs:\n",
    "    lemmatized_colloc = []\n",
    "    for word in colloc.split(' '):\n",
    "        lemma = lemmatizer.lemmatize(word)\n",
    "        lemmatized_colloc.append(lemma)\n",
    "    lemmatized_collocs.append(' '.join(lemmatized_colloc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0\n",
    "for test_colloc in topmine_collocs:\n",
    "    if test_colloc in collocs:\n",
    "        score += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "933"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22075"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topmine_collocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3646"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall:\t\t 0.25589687328579264\n"
     ]
    }
   ],
   "source": [
    "recall = score / len(collocs)\n",
    "print('recall:\\t\\t', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:\t 0.042265005662514156\n"
     ]
    }
   ],
   "source": [
    "precision = score / len(topmine_collocs)\n",
    "print('precision:\\t', precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
