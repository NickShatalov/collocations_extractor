Category utility is a measure of "category goodness" defined in and . It attempts to maximize both the probability that two objects in the same category have attribute values in common, and the probability that objects from different categories have different attribute values. It was intended to supersede more limited measures of category goodness such as "cue validity" (; ) and "collocation index" . It provides a normative information-theoretic measure of the "predictive advantage" gained by the observer who possesses knowledge of the given category structure (i.e., the class labels of instances) over the observer who does "not" possess knowledge of the category structure. In this sense the motivation for the "category utility" measure is similar to the information gain metric used in decision tree learning. In certain presentations, it is also formally equivalent to the mutual information, as discussed below. A review of "category utility" in its probabilistic incarnation, with applications to machine learning, is provided in .

The probability-theoretic definition of "category utility" given in and is as follows:

where formula_2 is a size-formula_3 set of formula_4-ary features, and formula_5 is a set of formula_6 categories. The term formula_7 designates the marginal probability that feature formula_8 takes on value formula_9, and the term formula_10 designates the category-conditional probability that feature formula_8 takes on value formula_9 "given" that the object in question belongs to category formula_13.

The motivation and development of this expression for "category utility", and the role of the multiplicand formula_14 as a crude overfitting control, is given in the above sources. Loosely , the term formula_15 is the expected number of attribute values that can be correctly guessed by an observer using a probability-matching strategy together with knowledge of the category labels, while formula_16 is the expected number of attribute values that can be correctly guessed by an observer the same strategy but without any knowledge of the category labels. Their difference therefore reflects the relative advantage accruing to the observer by having knowledge of the category structure.

The information-theoretic definition of "category utility" for a set of entities with size-formula_3 binary feature set formula_2, and a binary category formula_19 is given in as follows:

where formula_21 is the prior probability of an entity belonging to the positive category formula_22 (in the absence of any feature information), formula_23 is the conditional probability of an entity having feature formula_8 given that the entity belongs to category formula_22, formula_26 is likewise the conditional probability of an entity having feature formula_8 given that the entity belongs to category formula_28, and formula_29 is the prior probability of an entity possessing feature formula_8 (in the absence of any category information).

The intuition behind the above expression is as follows: The term formula_31 represents the cost (in bits) of optimally encoding (or transmitting) feature information when it known that the objects to be described belong to category formula_22. Similarly, the term formula_33 represents the cost (in bits) of optimally encoding (or transmitting) feature information when it known that the objects to be described belong to category formula_28. The sum of these two terms in the brackets is therefore the weighted average of these two costs. The final term, formula_35, represents the cost (in bits) of optimally encoding (or transmitting) feature information when no category information is available. The value of the "category utility" will, in the above formulation, be negative (???).

It is mentioned in and that the category utility is equivalent to the mutual information. Here we provide a simple demonstration of the nature of this equivalence. Let us assume a set of entities each having the same formula_36 features, i.e., feature set formula_2, with each feature variable having cardinality formula_38. That is, each feature has the capacity to adopt any of formula_38 distinct values (which need "not" be ordered; all variables can be nominal); for the special case formula_40 these features would be considered "binary", but more generally, for any formula_38, the features are simply "m-ary". For our purposes, without loss of generality, we can replace feature set formula_42 with a single aggregate variable formula_43 that has cardinality formula_44, and adopts a unique value formula_45 corresponding to each feature combination in the Cartesian product formula_46. (Ordinality does "not" matter, because the mutual information is not sensitive to ordinality.) In what follows, a term such as formula_47 or simply formula_48 refers to the probability with which formula_43 adopts the particular value formula_50. (Using the aggregate feature variable formula_43 replaces multiple summations, and simplifies the presentation to follow.)

We assume also a single category variable formula_52, which has cardinality formula_53. This is equivalent to a classification system in which there are formula_53 non-intersecting categories. In the special case of formula_55 we have the two-category case discussed above. From the definition of mutual information for discrete variables, the mutual information formula_56 between the aggregate feature variable formula_43 and the category variable formula_52 is given by:

where formula_48 is the prior probability of feature variable formula_43 adopting value formula_50, formula_63 is the marginal probability of category variable formula_52 adopting value formula_65, and formula_66 is the joint probability of variables formula_43 and formula_52 simultaneously adopting those respective values. In terms of the conditional probabilities this can be re-written (or defined) as

If we will rewrite the original definition of the category utility from above, with formula_19, we have

This equation clearly has the same form as the (blue) equation expressing the mutual information between the feature set and the category variable; the difference is that the sum formula_72 in the "category utility" equation runs over independent binary variables formula_2, whereas the sum formula_74 in the mutual information runs over "values" of the single formula_44-ary variable formula_43. The two measures are actually equivalent then "only" when the features formula_77, are "independent" (and assuming that terms in the sum corresponding to formula_78 are also added).

Like the mutual information, the "category utility" is not sensitive to any "ordering" in the feature or category variable values. That is, as far as the "category utility" is concerned, the category set codice_1 is not qualitatively different from the category set codice_2 since the formulation of the "category utility" does not account for any ordering of the class variable. Similarly, a feature variable adopting values codice_3 is not qualitatively different from a feature variable adopting values codice_4. As far as the "category utility" or "mutual information" are concerned, "all" category and feature variables are "nominal variables." For this reason, "category utility" does not reflect any "gestalt" aspects of "category goodness" that might be based on such ordering effects. One possible adjustment for this insensitivity to ordinality is given by the weighting scheme described in the article for mutual information.

This section provides some background on the origins of, and need for, formal measures of "category goodness" such as the "category utility", and some of the history that lead to the development of this particular metric.

At least since the time of Aristotle there has been a tremendous fascination in philosophy with the nature of concepts and universals. What kind of "entity" is a concept such as "horse"? Such abstractions do not designate any particular individual in the world, and yet we can scarcely imagine being able to comprehend the world without their use. Does the concept "horse" therefore have an independent existence outside of the mind? If it does, then what is the locus of this independent existence? The question of locus was an important issue on which the classical schools of Plato and Aristotle famously differed. However, they remained in agreement that universals "did" indeed have a mind-independent existence. There was, therefore, always a "fact to the matter" about which concepts and universals exist in the world.

In the late Middle Ages (perhaps beginning with Occam, although Porphyry also makes a much earlier remark indicating a certain discomfort with the status quo), however, the certainty that existed on this issue began to erode, and it became acceptable among the so-called nominalists and empiricists to consider concepts and universals as strictly mental entities or conventions of language. On this view of concepts—that they are purely representational constructs—a new question then comes to the fore: "Why do we possess one set of concepts rather than another?" What makes one set of concepts "good" and another set of concepts "bad"? This is a question that modern philosophers, and subsequently machine learning theorists and cognitive scientists, have struggled with for many decades.

One approach to answering such questions is to investigate the "role" or "purpose" of concepts in cognition. Thus, we ask: "What are concepts good for in the first place?" The answer provided by and many others is that classification (conception) is a precursor to "induction": By imposing a particular categorization on the universe, an organism gains the ability to deal with physically non-identical objects or situations in an identical fashion, thereby gaining substantial predictive leverage (;). As J.S. Mill puts it ,

From this base, Mill reaches the following conclusion, which foreshadows much subsequent thinking about category goodness, including the notion of "category utility":

One may compare this to the "category utility hypothesis" proposed by : "A category is useful to the extent that it can be expected to improve the ability of a person to accurately predict the features of instances of that category." Mill here seems to be suggesting that the best category structure is one in which object features (properties) are maximally informative about the object's class, and, simultaneously, the object class is maximally informative about the object's features. In other words, a useful classification scheme is one in which we can use category knowledge to accurately infer object properties, and we can use property knowledge to accurately infer object classes. One may also compare this idea to Aristotle's criterion of "counter-predication" for definitional predicates, as well as to the notion of concepts described in formal concept analysis.

A variety of different measures have been suggested with an aim of formally capturing this notion of "category goodness," the best known of which is probably the "cue validity". Cue validity of a feature formula_8 with respect to category formula_13 is defined as the conditional probability of the category given the feature (;;), formula_81, or as the deviation of the conditional probability from the category base rate (;), formula_82. Clearly, these measures quantify only inference from feature to category (i.e., "cue validity"), but not from category to feature, i.e., the "category validity" formula_83. Also, while the cue validity was originally intended to account for the demonstrable appearance of "basic categories" in human cognition—categories of a particular level of generality that are evidently preferred by human learners—a number of major flaws in the cue validity quickly emerged in this regard (;;, and others).

One attempt to address both problems by simultaneously maximizing both feature validity and category validity was made by in defining the "collocation index" as the product formula_84, but this construction was fairly "ad hoc" (see ). The "category utility" was introduced as a more sophisticated refinement of the cue validity, which attempts to more rigorously quantify the full inferential power of a class structure. As shown above, on a certain view the category utility is equivalent to the mutual information between the feature variable and the category variable. It has been suggested that categories having the greatest overall "category utility" are those that are not only those "best" in a normative sense, but also those human learners prefer to use, e.g., "basic" categories . Other related measures of category goodness are "cohesion" (;) and "salience" .



