{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import artm\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION = './Data/Component_Results/syntaxnet/lemmatized_collection/'\n",
    "TOPMINE_OUTPUT = './Data/Component_Results/topmine/topmine.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "filenames = []\n",
    "\n",
    "for filename in os.listdir(COLLECTION):\n",
    "    filenames.append(filename.split('.')[0])\n",
    "    \n",
    "    with open(COLLECTION + \"/\" + filename, \"r\") as f:\n",
    "        doc = f.read()\n",
    "        doc = re.sub(r'\\.', '', doc)\n",
    "        doc = re.sub(r' +', ' ', doc)\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "topmine_df = pd.read_csv(TOPMINE_OUTPUT, sep='\\t')\n",
    "collocs = list(topmine_df['ngramm'])\n",
    "del topmine_df\n",
    "\n",
    "# with open(COLLOCS, 'r') as f:\n",
    "#     collocs = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in tqdm(documents):\n",
    "    words = document.split(' ')\n",
    "    i = 0\n",
    "    while True:\n",
    "        flag = False\n",
    "        for colloc in collocs:\n",
    "            colloc_words = colloc.split(' ')\n",
    "            candidate = words[i:i + len(colloc_words)]\n",
    "            if candidate == colloc_words:\n",
    "                i += len(colloc_words)\n",
    "                flag = True\n",
    "                break\n",
    "        if not flag:\n",
    "            new_document.append(words[i])\n",
    "            i += 1\n",
    "        if i >= len(words):\n",
    "            break\n",
    "    new_documents.append(new_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [42:32<00:00, 12.89s/it]\n"
     ]
    }
   ],
   "source": [
    "new_documents = []\n",
    "for document in tqdm(documents):\n",
    "    new_document = []\n",
    "    words = document.split(' ')\n",
    "    i = 0\n",
    "    while True:\n",
    "        flag = False\n",
    "        for colloc in collocs:\n",
    "            colloc_words = colloc.split(' ')\n",
    "            candidate = words[i:i + len(colloc_words)]\n",
    "            if candidate == colloc_words:\n",
    "                new_document.append('_'.join(candidate))\n",
    "                i += len(colloc_words)\n",
    "                flag = True\n",
    "                break\n",
    "        if not flag:\n",
    "            new_document.append(words[i])\n",
    "            i += 1\n",
    "        if i >= len(words):\n",
    "            break\n",
    "    new_documents.append(new_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [' '.join(doc) for doc in new_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(min_df=0, max_df=1.0)\n",
    "X_test = cv.fit_transform(docs)\n",
    "tokens = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 27445)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убираем часто встречаемые\n",
    "N = 30\n",
    "counts = X_test.toarray().sum(axis=0)\n",
    "inds = np.argpartition(-counts, np.arange(N))[:N]\n",
    "# inds = np.array(inds.tolist()[0])[:N]\n",
    "\n",
    "stopwords = []\n",
    "for i in inds:\n",
    "    stopwords.append(tokens[i])\n",
    "    \n",
    "# Убираем редко встречаемые\n",
    "# inds = counts <= 2\n",
    "# inds = inds.nonzero()[0]\n",
    "# for i in inds:\n",
    "#     stopwords.append(tokens[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(min_df=0, max_df=1.0, stop_words=stopwords)\n",
    "X = cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 27415)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowpal_documents = []\n",
    "for row, filename in zip(X, filenames):\n",
    "    vowpal_doc = [filename, '|']\n",
    "    for count, token in zip(row.toarray()[0], cv.get_feature_names()):\n",
    "        if count != 0:\n",
    "            vowpal_doc.append(\"{}:{}\".format(token, count))\n",
    "    vowpal_documents.append(' '.join(vowpal_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOWPAL_DOCS = 'vowpal_docs.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VOWPAL_DOCS, 'w') as f:\n",
    "    f.write('\\n'.join(vowpal_documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "docword = [str(len(filenames)), str(X.shape[1]), '1']\n",
    "for doc_id, row in enumerate(X):\n",
    "    for word_id, count in enumerate(row.toarray()[0]):\n",
    "        if count != 0:\n",
    "            docword.append(\"{} {} {}\".format(doc_id + 1, word_id + 1, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCWORD = 'docword.wiki.txt'\n",
    "VOCAB = 'vocab.wiki.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DOCWORD, 'w') as f:\n",
    "    f.write('\\n'.join(docword))\n",
    "\n",
    "with open(VOCAB, 'w') as f:\n",
    "    f.write('\\n'.join(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_NUM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import artm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_vectorizer = artm.BatchVectorizer(data_path=VOWPAL_DOCS,\n",
    "                                        data_format='vowpal_wabbit',\n",
    "                                        collection_name='wiki',\n",
    "                                        target_folder='artm_folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = batch_vectorizer.dictionary\n",
    "topic_names = ['topic_{}'.format(i) for i in range(TOPIC_NUM)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artm = artm.ARTM(topic_names=topic_names, cache_theta=True,\n",
    "                       scores=[artm.PerplexityScore(name='PerplexityScore',\n",
    "                                                    dictionary=dictionary)],\n",
    "                       regularizers=[artm.SmoothSparseThetaRegularizer(name='SparseTheta',\n",
    "                                                                       tau=-0.15),\n",
    "                                     artm.DecorrelatorPhiRegularizer(name='Decorrelator',\n",
    "                                                                     tau=0.1)]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artm.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore'))\n",
    "model_artm.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
    "model_artm.scores.add(artm.TopicKernelScore(name='TopicKernelScore',\n",
    "                                                  probability_mass_threshold=0.3))\n",
    "model_artm.scores.add(artm.TopTokensScore(name='TopTokensScore', num_tokens=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artm.initialize(dictionary=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 533 ms, total: 13.1 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0: \n",
      "['algorithm', 'problem', 'instance', 'then', 'we', 'learn']\n",
      "topic_1: \n",
      "['between', 'machine_learn', 'data', 'model', 'distribution', 'may']\n",
      "topic_2: \n",
      "['model', 'all', 'learn', 'when', 'set', 'these']\n",
      "topic_3: \n",
      "['when', 'algorithm', 'there', 'data', 'their', 'than']\n",
      "topic_4: \n",
      "['other', 'these', 'some', 'between', 'we', 'all']\n",
      "topic_5: \n",
      "['probability', 'then', 'all', 'algorithm', 'data', 'some']\n",
      "topic_6: \n",
      "['learn', 'model', 'some', 'machine_learn', 'but', 'these']\n",
      "topic_7: \n",
      "['model', 'we', 'all', 'other', 'but', 'example']\n",
      "topic_8: \n",
      "['then', 'we', 'some', 'model', 'all', 'there']\n",
      "topic_9: \n",
      "['these', 'there', 'but', 'example', 'some', 'algorithm']\n"
     ]
    }
   ],
   "source": [
    "for topic_name in model_artm.topic_names:\n",
    "    print(topic_name + ': ')\n",
    "    print(model_artm.score_tracker['TopTokensScore'].last_tokens[topic_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nwt = model_artm.get_phi(model_name=model_artm.model_nwt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ptw = (df_nwt.T / df_nwt.sum(axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = dict()\n",
    "no_collocs = []\n",
    "for colloc in collocs:\n",
    "    index = '_'.join(colloc.split(' '))\n",
    "    if index in df_ptw.index:\n",
    "        res_dict[colloc] = df_ptw.loc[index].values\n",
    "    else:\n",
    "        no_collocs.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9567"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_collocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def js(p, q):\n",
    "    p = np.asarray(p)\n",
    "    q = np.asarray(q)\n",
    "   # normalize\n",
    "    p /= p.sum()\n",
    "    q /= q.sum()\n",
    "    m = (p + q) / 2\n",
    "    return (entropy(p, m) + entropy(q, m)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deg_func(p, gamma=2):\n",
    "    return np.power(p, gamma).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 2\n",
    "\n",
    "ngrams = []\n",
    "kl_divs = []\n",
    "js_divs = []\n",
    "degs = []\n",
    "\n",
    "for ngram, distrib in res_dict.items():\n",
    "    ngrams.append(ngram)\n",
    "    kl_divs.append(entropy(distrib, np.ones(TOPIC_NUM) / TOPIC_NUM))\n",
    "    js_divs.append(js(distrib, np.ones(TOPIC_NUM) / TOPIC_NUM))\n",
    "    degs.append(deg_func(distrib, GAMMA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic = pd.DataFrame({'ngramm': ngrams, 'kl_div': kl_divs, 'js_div': js_divs, 'deg': degs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic.to_csv('./Data/Component_Results/bigartm/bigartm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = 'machine learn'\n",
    "plt.ylim((0, 1))\n",
    "plt.title('p(t|w) = {}'.format(c))\n",
    "plt.bar(range(TOPIC_NUM), height=res_dict[c])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
