{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Курсовая работа\n",
    "1. [Сборка датасета](#dataset_collect)\n",
    "    1. [Коллокации](#collocations_collect) (для оценки качества)\n",
    "    2. [Документы](#documents_collect)\n",
    "2. [SyntaxNet](#syntaxnet)\n",
    "    1. [Запуск SyntaxNet](#syntaxnet_run)\n",
    "    2. [Обработка результатов SyntaxNet'а](#syntaxnet_postprocess)\n",
    "    \n",
    "    #### To be done...\n",
    "3. Запуск TopMine\n",
    "4. Запуск тематической модели\n",
    "5. Обучение итоговой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import json\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WIKI_XML = \"../wiki.xml\"\n",
    "WIKIEXTRACTOR_FOLDER = \"../wikiextractor/\"\n",
    "WIKITEXTS_JSON_FOLDER = \"../wikitexts_json/\"\n",
    "\n",
    "WIKI_COLLECTION = \"../collection/\"\n",
    "COLLOCS_FILE = \"../collocs.txt\"\n",
    "\n",
    "SYNTAXNET_INPUT = \"../sentences.txt\"\n",
    "SYNTAXNET_OUTPUT = \"../syntaxnet_out.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataset_collect'></a>\n",
    "# Сборка датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='collocations_collect'></a>\n",
    "## Коллокации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выделяем текст статьи из xml файла**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(WIKI_XML, \"r\") as f:\n",
    "    data_xml = f.read().replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data_xml, \"xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [tmp.text for tmp in soup.find_all('text')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выделяем гиперссылки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperlinks = []\n",
    "for text in texts:\n",
    "    for open_brackets, close_brackets in zip(re.finditer('\\[\\[', text), re.finditer('\\]\\]', text)):\n",
    "        start_ind = open_brackets.span()[1]\n",
    "        close_ind = close_brackets.span()[0]\n",
    "        hyperlinks.append(text[start_ind:close_ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Фильтруем теги, разбиваем ссылки с множественными словами**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_hyperlinks = []\n",
    "for hl in hyperlinks:\n",
    "    # --- Теги ---\n",
    "    # Игнорируем, если тег File:\n",
    "    if re.match(\"File:\", hl) and (re.match(\"File:\", hl).span()[0] == 0):\n",
    "        continue\n",
    "    # Добавляем имя категории из тега Category:\n",
    "    if re.match(\"Category:\", hl) and (re.match(\"Category:\", hl).span()[0] == 0):\n",
    "        filtered_hyperlinks.append(hl[re.match(\"Category:\", hl).span()[1]:])\n",
    "        continue\n",
    "    \n",
    "    # --- НеТеги ---\n",
    "    # Убираем все что в скобках\n",
    "    hl = re.sub(\"\\(.+\\)\", \"\", hl)\n",
    "    # Разделяем мультиназвания (через | или and) на раздельные коллокации\n",
    "    sub_hl = list(re.split(\"\\|| and \", hl))\n",
    "    \n",
    "    filtered_hyperlinks += sub_hl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Окончательная обработка, получаем коллокации**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collocs = []\n",
    "for hl in filtered_hyperlinks:\n",
    "    hl = hl.strip()\n",
    "    hl = hl.lower()\n",
    "    \n",
    "    # Если это инициалы -> не добавляем\n",
    "    if re.match(\"(.\\. .\\. .+)|(.+ .\\. .+)\", hl) and (len(hl.split(' ')) == 3):\n",
    "        continue\n",
    "        \n",
    "    hl = re.sub(\" +\", \" \", hl)\n",
    "    hl = re.sub(\"[^ A-Za-z-]+\", \"\", hl)\n",
    "    hl = hl.strip()\n",
    "    \n",
    "    flag = (hl not in collocs) and \\\n",
    "           (len(hl.split(' ')) > 1) and \\\n",
    "           (len(hl.split(' ')) < 5)\n",
    "    if flag:\n",
    "        collocs.append(hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['computer scientist',\n",
       " 'mikhail moiseevich bongard',\n",
       " 'pattern recognition',\n",
       " 'gdel escher bach',\n",
       " 'douglas hofstadter',\n",
       " 'harry foundalis',\n",
       " 'fluid concepts',\n",
       " 'creative analogies',\n",
       " 'artificial intelligence',\n",
       " 'machine learning',\n",
       " 'cognitive science',\n",
       " 'cognitive psychology',\n",
       " 'computer-related introductions in',\n",
       " 'statistical classification',\n",
       " 'classification rule',\n",
       " 'statistical model',\n",
       " 'observable variable',\n",
       " 'target variable',\n",
       " 'joint probability distribution',\n",
       " 'discriminative model',\n",
       " 'conditional probability',\n",
       " 'linear classifier',\n",
       " 'naive bayes classifier',\n",
       " 'linear discriminant analysis',\n",
       " 'logistic regression',\n",
       " 'support vector machine',\n",
       " 'continuous variable',\n",
       " 'discrete variable',\n",
       " 'target function',\n",
       " 'marginal distribution',\n",
       " 'probability distribution',\n",
       " 'bayes rule',\n",
       " 'regression analysis',\n",
       " 'gaussian mixture model',\n",
       " 'mixture model',\n",
       " 'hidden markov model',\n",
       " 'stochastic context-free grammar',\n",
       " 'probabilistic context-free grammar',\n",
       " 'naive bayes',\n",
       " 'averaged one-dependence estimators',\n",
       " 'latent dirichlet allocation',\n",
       " 'restricted boltzmann machine',\n",
       " 'generative adversarial networks',\n",
       " 'maximum likelihood estimation',\n",
       " 'maximize the data likelihood',\n",
       " 'support vector machines',\n",
       " 'maximum-entropy markov model',\n",
       " 'conditional random field',\n",
       " 'neural network',\n",
       " 'empirical measure',\n",
       " 'graphical model',\n",
       " 'bell system technical journal',\n",
       " 'massachusetts institute of technology',\n",
       " 'statistical models',\n",
       " 'probabilistic models',\n",
       " 'learning algorithm',\n",
       " 'occams razor',\n",
       " 'mathematical logic',\n",
       " 'artificial neural networks',\n",
       " 'conditional independence',\n",
       " 'bayesian inference',\n",
       " 'no free lunch',\n",
       " 'minimum description length',\n",
       " 'feature space',\n",
       " 'feature selection',\n",
       " 'k-nearest neighbors algorithm',\n",
       " 'cognitive bias',\n",
       " 'graphical models',\n",
       " 'bayesian statistics',\n",
       " 'categorical data',\n",
       " 'statistical classificationalgorithms',\n",
       " 'data mining algorithms',\n",
       " 'program optimization',\n",
       " 'organic evolution',\n",
       " 'genetic recombination',\n",
       " 'natural selection',\n",
       " 'optimization algorithms and methods',\n",
       " 'evolutionary computation',\n",
       " 'artificial life models',\n",
       " 'digital organisms',\n",
       " 'cluster analysis',\n",
       " 'supervised learning',\n",
       " 'labeled data',\n",
       " 'unsupervised learning',\n",
       " 'independent identically distributed',\n",
       " 'independently identically distributed',\n",
       " 'transductive learning',\n",
       " 'inductive reasoning',\n",
       " 'inductive learning',\n",
       " 'vapniks principle',\n",
       " 'decision boundary',\n",
       " 'decision boundaries',\n",
       " 'feature learning',\n",
       " 'curse of dimensionality',\n",
       " 'vladimir vapnik',\n",
       " 'probably approximately correct learning',\n",
       " 'bayes theorem',\n",
       " 'joint distribution',\n",
       " 'chain rule',\n",
       " 'transductive support vector machine',\n",
       " 'hinge loss',\n",
       " 'reproducing kernel hilbert space',\n",
       " 'empirical risk minimization',\n",
       " 'empirical risk',\n",
       " 'convex function',\n",
       " 'manifold regularization',\n",
       " 'tikhonov regularization',\n",
       " 'laplacian matrix',\n",
       " 'graph laplacian',\n",
       " 'distance metric',\n",
       " 'kernelin non-parametric statistics',\n",
       " 'concept learning',\n",
       " 'pu learning',\n",
       " 'stochastic process',\n",
       " 'markov decision process',\n",
       " 'michael lvovitch tsetlin',\n",
       " 'reinforcement learning',\n",
       " 'markov decision processpolicy iteration',\n",
       " 'policy iterators',\n",
       " 'evolutionary algorithm',\n",
       " 'computable function',\n",
       " 'markov process',\n",
       " 'real numbers',\n",
       " 'game theory',\n",
       " 'automata theory',\n",
       " 'control theory',\n",
       " 'machine learningresearchers',\n",
       " 'artificial intelligence researchers',\n",
       " 'statistical modeling method',\n",
       " 'structured prediction',\n",
       " 'natural language processing',\n",
       " 'markov random field',\n",
       " 'sequence labeling',\n",
       " 'biological sequences',\n",
       " 'computer vision',\n",
       " 'shallow parsing',\n",
       " 'named entity recognition',\n",
       " 'gene prediction',\n",
       " 'gene finding',\n",
       " 'andrew mccallum',\n",
       " 'random variable',\n",
       " 'markov property',\n",
       " 'undirected graphical model',\n",
       " 'markov random fieldinference',\n",
       " 'forward-backward algorithm',\n",
       " 'viterbi algorithm',\n",
       " 'loopy belief propagation',\n",
       " 'linear programming relaxation',\n",
       " 'maximum likelihood',\n",
       " 'gradient descent',\n",
       " 'quasi-newton method',\n",
       " 'likelihood function',\n",
       " 'structured svm',\n",
       " 'structured support vector machine',\n",
       " 'latent variable model',\n",
       " 'chain rule of probability',\n",
       " 'structured perceptron',\n",
       " 'gesture recognition',\n",
       " 'c sharp',\n",
       " 'net framework',\n",
       " 'association for computational linguistics',\n",
       " 'hammersleyclifford theorem',\n",
       " 'maximum entropy markov model',\n",
       " 'lise getoor',\n",
       " 'mathematical model',\n",
       " 'neural net',\n",
       " 'stochastic gradient descent',\n",
       " 'array data structure',\n",
       " 'variable selection',\n",
       " 'estimation theory',\n",
       " 'early stopping',\n",
       " 'mean squared error',\n",
       " 'datasets in machine learning',\n",
       " 'validity statistics',\n",
       " 'reuven rubinstein',\n",
       " 'monte carlo method',\n",
       " 'monte carlo',\n",
       " 'combinatorial optimization',\n",
       " 'continuous optimization',\n",
       " 'importance sampling',\n",
       " 'traveling salesman problem',\n",
       " 'quadratic assignment problem',\n",
       " 'sequence alignment',\n",
       " 'dna sequence alignment',\n",
       " 'global optimization',\n",
       " 'cross entropy',\n",
       " 'kullbackleibler divergence',\n",
       " 'parametric family',\n",
       " 'probability density function',\n",
       " 'exponential family',\n",
       " 'natural exponential family',\n",
       " 'discrete space',\n",
       " 'maximum likelihood estimator',\n",
       " 'gaussian distribution',\n",
       " 'estimation of distribution algorithm',\n",
       " 'simulated annealing',\n",
       " 'genetic algorithms',\n",
       " 'harmony search',\n",
       " 'tabu search',\n",
       " 'randomized algorithm',\n",
       " 'monte carlo methods',\n",
       " 'predictive analytics',\n",
       " 'fraud detection',\n",
       " 'binary numeral system',\n",
       " 'weather prediction',\n",
       " 'online shop',\n",
       " 'predictive modelling',\n",
       " 'predictive model',\n",
       " 'finite model',\n",
       " 'physical law',\n",
       " 'laws of nature',\n",
       " 'biological processes',\n",
       " 'ecml pkdd',\n",
       " 'data stream mining',\n",
       " 'data mining',\n",
       " 'predictive models',\n",
       " 'predictive power',\n",
       " 'insurance fraud',\n",
       " 'table of confusion',\n",
       " 'loss function',\n",
       " 'receiver operating characteristic',\n",
       " 'university of twente',\n",
       " 'statistical paradoxes',\n",
       " 'jerome bruner',\n",
       " 'exemplar theory',\n",
       " 'version spaces',\n",
       " 'statistical learning theory',\n",
       " 'pac learning',\n",
       " 'information theory',\n",
       " 'algorithmic information theory',\n",
       " 'data compression',\n",
       " 'classical conditioning',\n",
       " 'ivan pavlov',\n",
       " 'clark hull',\n",
       " 'behavioral psychology',\n",
       " 'george armitage miller',\n",
       " 'george miller',\n",
       " 'factor analysis',\n",
       " 'karl lashley',\n",
       " 'donald hebb',\n",
       " 'perceptual learning',\n",
       " 'prototype theory',\n",
       " 'mental representation',\n",
       " 'john robert anderson',\n",
       " 'joshua tenenbaum',\n",
       " 'sample exclusion dimension',\n",
       " 'learning theory education',\n",
       " 'adaptive control',\n",
       " 'developmental robotics',\n",
       " 'university of washington',\n",
       " 'object recognition',\n",
       " 'stanford university',\n",
       " 'world wide web',\n",
       " 'european union',\n",
       " 'google x',\n",
       " 'cognitive robotics',\n",
       " 'evolutionary robotics',\n",
       " 'juergen schmidhuber',\n",
       " 'technical university of munich',\n",
       " 'peter nordin',\n",
       " 'chalmers university of technology',\n",
       " 'university of massachusetts amherst',\n",
       " 'carnegie mellon university',\n",
       " 'university of bonn',\n",
       " 'cornell university',\n",
       " 'italian institute of technology',\n",
       " 'delft university of technology',\n",
       " 'robot controllearning',\n",
       " 'imageversion spacepng',\n",
       " 'symbolic artificial intelligence',\n",
       " 'binary classification',\n",
       " 'logical sentences',\n",
       " 'logical disjunction',\n",
       " 'state space search',\n",
       " 'solution search',\n",
       " 'formal concept analysis',\n",
       " 'inductive logic programming',\n",
       " 'rough set',\n",
       " 'inductive logic',\n",
       " 'leslie valiant',\n",
       " 'pac learnability',\n",
       " 'character recognition',\n",
       " 'no free lunch theorem',\n",
       " 'information processing',\n",
       " 'knowledge extraction',\n",
       " 'derivation of knowledge',\n",
       " 'similarity measure',\n",
       " 'satellite images',\n",
       " 'arithmetic precision',\n",
       " 'domain knowledge',\n",
       " 'logical implication',\n",
       " 'information entropy',\n",
       " 'principal component analysis',\n",
       " 'multidimensional scaling',\n",
       " 'structural equation modeling',\n",
       " 'dimensionality reduction',\n",
       " 'projection pursuit',\n",
       " 'independent component analysis',\n",
       " 'data clustering',\n",
       " 'measure of similarity',\n",
       " 'linear correlation',\n",
       " 'mutual information',\n",
       " 'joint entropy',\n",
       " 'database systems',\n",
       " 'olap aggregation',\n",
       " 'business intelligence',\n",
       " 'rough sets',\n",
       " 'fuzzy sets',\n",
       " 'value-attribute system',\n",
       " 'value granulation',\n",
       " 'lotfi zadeh',\n",
       " 'akaike information criterion',\n",
       " 'bayesian information criterion',\n",
       " 'model regularization',\n",
       " 'type- fuzzy sets',\n",
       " 'beijing china',\n",
       " 'porto portugal',\n",
       " 'toronto ontario',\n",
       " 'journal of experimental',\n",
       " 'theoretical artificial intelligence',\n",
       " 'cambridge ma',\n",
       " 'tahoe city ca',\n",
       " 'new york city',\n",
       " 'chambry france',\n",
       " 'lyon france',\n",
       " 'fort lauderdale fl',\n",
       " 'dasarathy belur v',\n",
       " 'knowledge-based systems',\n",
       " 'theoretical computer science',\n",
       " 'decision strategy',\n",
       " 'base rates',\n",
       " 'bayesian decision theory',\n",
       " 'bayesian decision strategy',\n",
       " 'thompson sampling',\n",
       " 'new york',\n",
       " 'alexey chervonenkis',\n",
       " 'vc dimension',\n",
       " 'vapnikchervonenkis theory',\n",
       " 'model selection',\n",
       " 'occam learning',\n",
       " 'training data',\n",
       " 'eager learning',\n",
       " 'case-based reasoning',\n",
       " 'k-nearest neighbor algorithm',\n",
       " 'lazy learning',\n",
       " 'artificial neural network',\n",
       " 'offline learning',\n",
       " 'conditional probability distribution',\n",
       " 'generative model',\n",
       " 'generalized linear model',\n",
       " 'generalized linear regression',\n",
       " 'bernoulli distribution',\n",
       " 'categorical distribution',\n",
       " 'maximum entropy classifier',\n",
       " 'linear regression',\n",
       " 'random forest',\n",
       " 'regression models',\n",
       " 'garbage in garbage out',\n",
       " 'range error',\n",
       " 'missing values',\n",
       " 'data quality',\n",
       " 'quality of data',\n",
       " 'los altos california',\n",
       " 'computational biology',\n",
       " 'knowledge discovery',\n",
       " 'data cleaning',\n",
       " 'instance selection',\n",
       " 'data normalization',\n",
       " 'data transformation',\n",
       " 'feature extraction',\n",
       " 'training set',\n",
       " 'data cleansing',\n",
       " 'data editing',\n",
       " 'data reduction',\n",
       " 'data wrangling',\n",
       " 'computer science',\n",
       " 'dynamical system',\n",
       " 'dynamical systems',\n",
       " 'kernel methods',\n",
       " 'bayesian machine learning',\n",
       " 'variational bayesian methods',\n",
       " 'thomas minka',\n",
       " 'numerical digit',\n",
       " 'optical character recognition',\n",
       " 'multiple instance learning',\n",
       " 'multi-label classification',\n",
       " 'logical connective',\n",
       " 'identity of indiscernibles',\n",
       " 'hans christian andersen',\n",
       " 'the ugly duckling',\n",
       " 'satosi watanabe',\n",
       " 'exclusive or',\n",
       " 'denote false true negation',\n",
       " 'not conjunction',\n",
       " 'extension ref namewatanaberp',\n",
       " 'w respectivelyref',\n",
       " 'power set',\n",
       " 'bit array',\n",
       " 'binary encoded',\n",
       " 'propositional function',\n",
       " 'hamming distance',\n",
       " 'nelson goodman',\n",
       " 'metaphors referring to animals',\n",
       " 'metaphors referring to birds',\n",
       " 'computational learning theory',\n",
       " 'theory of computation',\n",
       " 'hans rademacher',\n",
       " 'rademacher distribution',\n",
       " 'function composition',\n",
       " 'identically independently distributed',\n",
       " 'lipschitz function',\n",
       " 'lipschitz constant',\n",
       " 'contraction mapping',\n",
       " 'convex hull',\n",
       " 'set family',\n",
       " 'growth function',\n",
       " 'dudleys theorem',\n",
       " 'dudleys entropy bound',\n",
       " 'vapnik-chervonenkis dimension',\n",
       " 'unit ball',\n",
       " 'covering number',\n",
       " 'normal distribution',\n",
       " 'identically distributed random variables',\n",
       " 'measures of complexity',\n",
       " 'high-dimensional space',\n",
       " 'three-dimensional space',\n",
       " 'physical space',\n",
       " 'dynamic optimization',\n",
       " 'numerical analysis',\n",
       " 'combinatorial explosion',\n",
       " 'mathematical space',\n",
       " 'unit interval',\n",
       " 'unit hypercube',\n",
       " 'backward induction',\n",
       " 'euclidean distance',\n",
       " 'gamma function',\n",
       " 'chi-squared distribution',\n",
       " 'real number',\n",
       " 'identically distributed',\n",
       " 'signal-to-noise ratio',\n",
       " 'nearest neighbor search',\n",
       " 'time series analysis',\n",
       " 'data set',\n",
       " 'directed graph',\n",
       " 'k-nn classifier',\n",
       " 'semi-supervised learning',\n",
       " 'information retrieval',\n",
       " 'anomaly detection',\n",
       " 'data snooping',\n",
       " 'bellman equation',\n",
       " 'clustering high-dimensional data',\n",
       " 'concentration of measure',\n",
       " 'dimension reduction',\n",
       " 'model order reduction',\n",
       " 'dynamic programming',\n",
       " 'fourier-related transforms',\n",
       " 'linear least squares',\n",
       " 'multilinear principal component analysis',\n",
       " 'multilinear pca',\n",
       " 'multilinear subspace learning',\n",
       " 'singular value decomposition',\n",
       " 'measurement error',\n",
       " 'big data',\n",
       " 'sensor networks',\n",
       " 'noisy text',\n",
       " 'statistical independence',\n",
       " 'probabilistic database',\n",
       " 'statistical theory',\n",
       " 'knowledge model',\n",
       " 'information integration',\n",
       " 'knowledge engineers',\n",
       " 'knowledge base',\n",
       " 'semantic matching',\n",
       " 'minimal mappings',\n",
       " 'university of waterloo',\n",
       " 'undergraduate degree',\n",
       " 'knowledge value chain',\n",
       " 'knowledge representation',\n",
       " 'online machine learning',\n",
       " 'online learning',\n",
       " 'incremental learning',\n",
       " 'statistical classifiers',\n",
       " 'classification algorithms',\n",
       " 'neural networks',\n",
       " 'fuzzy logic',\n",
       " 'model based recognition',\n",
       " 'leonid perlovsky',\n",
       " 'aesthetic emotions',\n",
       " 'penalty method',\n",
       " 'dynamic logic',\n",
       " 'latent semantic analysis',\n",
       " 'linear algebra',\n",
       " 'probabilistic latent semantic indexing',\n",
       " 'hidden markov models',\n",
       " 'markov chain',\n",
       " 'semantic analysis',\n",
       " 'statistical inference',\n",
       " 'granular computing',\n",
       " 'distribution laws',\n",
       " 'fiducial distribution',\n",
       " 'random variables',\n",
       " 'gaussian variable',\n",
       " 'posterior distribution',\n",
       " 'confidence intervals',\n",
       " 'random sample',\n",
       " 'students t distribution',\n",
       " 'central limit theorem',\n",
       " 'neuro-fuzzy system',\n",
       " 'computational learning',\n",
       " 'degrees of freedom',\n",
       " 'confidence level',\n",
       " 'complexity index',\n",
       " 'complexity indices',\n",
       " 'complexity indexdetail',\n",
       " 'detail of a class',\n",
       " 'uniform distribution',\n",
       " 'pareto distribution',\n",
       " 'sufficient statistics',\n",
       " 'well-behaved statistic',\n",
       " 'bootstrapping populations',\n",
       " 'population bootstrap',\n",
       " 'twisting propertiestwisting argument',\n",
       " 'twisting argument',\n",
       " 'algorithmic inferencesampling mechanism',\n",
       " 'sampling mechanism',\n",
       " 'cumulative distribution function',\n",
       " 'standard normal distribution',\n",
       " 'confidence interval',\n",
       " 'algorithmic inference',\n",
       " 'disjunctive normal form',\n",
       " 'conjunctive normal form',\n",
       " 'decision tree',\n",
       " 'attribute efficient learning',\n",
       " 'boolean data type',\n",
       " 'scientific model',\n",
       " 'association rule learning',\n",
       " 'decision rules',\n",
       " 'decision rule',\n",
       " 'hypothesis testing',\n",
       " 'horn clause',\n",
       " 'cn algorithm',\n",
       " 'stuart russell',\n",
       " 'peter norvig',\n",
       " 'big o notation',\n",
       " 'kernel method',\n",
       " 'kernel machines',\n",
       " 'radial basis function network',\n",
       " 'rbf networks',\n",
       " 'clinical decision support system',\n",
       " 'diagnostic tools',\n",
       " 'knowledge discovery in databases',\n",
       " 'analogical modeling',\n",
       " 'imageoverfitted datapng',\n",
       " 'a polynomial',\n",
       " 'statistical noise',\n",
       " 'selecting the model',\n",
       " 'cambridge university press',\n",
       " 'coefficient of determination',\n",
       " 'model comparison',\n",
       " 'prior distribution',\n",
       " 'bayesian priors',\n",
       " 'principle of parsimony',\n",
       " 'google scholar',\n",
       " 'journal of clinical epidemiology',\n",
       " 'proportional hazards models',\n",
       " 'american journal of epidemiology',\n",
       " 'john wiley  sons',\n",
       " 'one in ten rule',\n",
       " 'biasvariance tradeoff',\n",
       " 'freedmans paradox',\n",
       " 'explanatory variable',\n",
       " 'dependent variable',\n",
       " 'statistically significant',\n",
       " 'imageoverfitting svgsvg',\n",
       " 'journal of chemical information',\n",
       " 'causal relation',\n",
       " 'function approximation',\n",
       " 'robustness robust machine learning',\n",
       " 'minimum spanning tree',\n",
       " 'life-time of correlation',\n",
       " 'curve fitting',\n",
       " 'data dredging',\n",
       " 'the journal of investing',\n",
       " 'biodata mining',\n",
       " 'convergence in probability',\n",
       " 'asymptotic theory',\n",
       " 'statistical asymptotic theory',\n",
       " 'probability theory',\n",
       " 'law of large numbers',\n",
       " 'with high probability',\n",
       " 'expected value',\n",
       " 'vapnikchervonenkis dimension',\n",
       " 'shattering number',\n",
       " 'concept class',\n",
       " 'sauershelah lemma',\n",
       " 'chebyshevs inequality',\n",
       " 'national science foundation',\n",
       " 'mit computer science',\n",
       " 'artificial intelligence laboratory',\n",
       " 'computational neuroscience',\n",
       " 'ventral stream',\n",
       " 'visual cortex',\n",
       " 'tomaso poggio',\n",
       " 'visual perception',\n",
       " 'neuroscience research centers',\n",
       " 'cognitive neuroscience',\n",
       " 'brian matthews',\n",
       " 'phi coefficient',\n",
       " 'pearsons chi-square test',\n",
       " 'chi-square statistic',\n",
       " 'contingency table',\n",
       " 'confusion matrix',\n",
       " 'true positive',\n",
       " 'true negative',\n",
       " 'false positive',\n",
       " 'false negative',\n",
       " 'correlation coefficient',\n",
       " 'geometric mean',\n",
       " 'regression coefficient',\n",
       " 'youdens j statistic',\n",
       " 'cohens kappa',\n",
       " 'cramrs v',\n",
       " 'f score',\n",
       " 'pierre baldi',\n",
       " 'baldi p',\n",
       " 'information retrieval evaluation',\n",
       " 'computational chemistry',\n",
       " 'statistical ratios',\n",
       " 'oded regev',\n",
       " 'gdel prize',\n",
       " 'parity learning',\n",
       " 'lattice problems',\n",
       " 'computational hardness assumption',\n",
       " 'hardness assumption',\n",
       " 'public-key cryptography',\n",
       " 'public-key cryptosystems',\n",
       " 'modular arithmetic',\n",
       " 'linear function',\n",
       " 'field of reals',\n",
       " 'chinese remainder theorem',\n",
       " 'random self-reducibility',\n",
       " 'lattice problemsgapsvp',\n",
       " 'public-key cryptosystem',\n",
       " 'chosen-ciphertext attack',\n",
       " 'lattice-based cryptography',\n",
       " 'short integer solution problem',\n",
       " 'post-quantum cryptography',\n",
       " 'computational intelligence',\n",
       " 'virtual scientific community',\n",
       " 'jacek zurada',\n",
       " 'international research institutes',\n",
       " 'world wide web conference',\n",
       " 'ranking function',\n",
       " 'ranking models',\n",
       " 'mehryar mohri',\n",
       " 'partial order',\n",
       " 'document retrieval',\n",
       " 'collaborative filtering',\n",
       " 'sentiment analysis',\n",
       " 'online advertising',\n",
       " 'google searchwiki',\n",
       " 'vector space model',\n",
       " 'standard boolean model',\n",
       " 'boolean model',\n",
       " 'okapi bm',\n",
       " 'machine translation',\n",
       " 'recommender system',\n",
       " 'feature vector',\n",
       " 'bag of words',\n",
       " 'query level feature',\n",
       " 'language modeling',\n",
       " 'inverse document frequency',\n",
       " 'hits algorithm',\n",
       " 'feature engineering',\n",
       " 'information retrievalmean average precision',\n",
       " 'mean average precision',\n",
       " 'discounted cumulative gain',\n",
       " 'normalized discounted cumulative gain',\n",
       " 'mean reciprocal rank',\n",
       " 'kendalls tau',\n",
       " 'spearmans rank correlation coefficient',\n",
       " 'spearmans rho',\n",
       " 'microsoft research asia',\n",
       " 'ordinal regression',\n",
       " 'binary classifier',\n",
       " 'norbert fuhr',\n",
       " 'polynomial regression',\n",
       " 'text retrieval conference',\n",
       " 'neural information processing systems',\n",
       " 'web search engine',\n",
       " 'overture services inc',\n",
       " 'gradient boosting',\n",
       " 'microsoft research',\n",
       " 'search quality',\n",
       " 'oblivious decision tree',\n",
       " 'tom costello',\n",
       " 'open-source software',\n",
       " 'open source',\n",
       " 'apache solr',\n",
       " 'information retrieval techniques',\n",
       " 'ranking functions',\n",
       " 'bertrand russell',\n",
       " 'bayesian committee machine',\n",
       " 'manifold learning',\n",
       " 'max flow min cut',\n",
       " 'model validation',\n",
       " 'validation set',\n",
       " 'validation dataset',\n",
       " 'partition of a set',\n",
       " 'statistical sample',\n",
       " 'statistical population',\n",
       " 'euclidean vector',\n",
       " 'least squares',\n",
       " 'binomial coefficient',\n",
       " 'jackknife resampling',\n",
       " 'positive predictive value',\n",
       " 'root mean squared error',\n",
       " 'median absolute deviation',\n",
       " 'kernel regression',\n",
       " 'shermanmorrison formula',\n",
       " 'closed-form expression',\n",
       " 'press statistic',\n",
       " 'stock market prediction',\n",
       " 'predicting stock values',\n",
       " 'medical diagnosis',\n",
       " 'scientific reports',\n",
       " 'sci rep',\n",
       " 'forward chaining',\n",
       " 'k nearest neighbors',\n",
       " 'gene expression',\n",
       " 'bootstrap aggregating',\n",
       " 'regression variable selection',\n",
       " 'jean piaget',\n",
       " 'gary drescher',\n",
       " 'jeff hawkins',\n",
       " 'memory-prediction framework',\n",
       " 'on intelligence',\n",
       " 'learning algorithms',\n",
       " 'conditional distribution',\n",
       " '- loss function',\n",
       " 'indicator notation',\n",
       " 'agnostic learning',\n",
       " 'mathematical optimization',\n",
       " 'linearly separable',\n",
       " 'geoff hinton',\n",
       " 'density estimation',\n",
       " 'mixture models',\n",
       " 'hierarchical clustering',\n",
       " 'deep belief network',\n",
       " 'deep belief nets',\n",
       " 'hebbian learning',\n",
       " 'self-organizing map',\n",
       " 'expectationmaximization algorithm',\n",
       " 'method of moments',\n",
       " 'blind signal separation',\n",
       " 'non-negative matrix factorization',\n",
       " 'ranjan acharyya',\n",
       " 'acharyya ranjan',\n",
       " 'spike-timing-dependent plasticity',\n",
       " 'adaptive resonance theory',\n",
       " 'automatic target recognition',\n",
       " 'topic modeling',\n",
       " 'generative topographic map',\n",
       " 'multivariate analysis',\n",
       " 'hebbian theory',\n",
       " 'duda richard o',\n",
       " 'hart peter e',\n",
       " 'pattern classification',\n",
       " 'geoffrey hinton',\n",
       " 'hinton geoffrey',\n",
       " 'sejnowski terrence j',\n",
       " 'mit press',\n",
       " 'optimal decisions',\n",
       " 'inductive bias',\n",
       " 'bias-variance dilemma',\n",
       " 'inductive transfer',\n",
       " 'learning to learn',\n",
       " 'learning classifier system',\n",
       " 'constraint satisfaction',\n",
       " 'applied behavioral analysis',\n",
       " 'slot machines',\n",
       " 'annals of applied probability',\n",
       " 'stochastic scheduling',\n",
       " 'pharmaceutical industry',\n",
       " 'pharmaceutical company',\n",
       " 'herbert robbins',\n",
       " 'gittins index',\n",
       " 'clinical trial',\n",
       " 'adaptive routing',\n",
       " 'financial portfolio design',\n",
       " 'world war ii',\n",
       " 'peter whittle',\n",
       " 'siam journal on computing',\n",
       " 'michael katehakis',\n",
       " 'greedy algorithm',\n",
       " 'softmax function',\n",
       " 'medical ethics',\n",
       " 'physicians duty',\n",
       " 'nonparametric regression',\n",
       " 'voting paradoxes',\n",
       " 'condorcet winner',\n",
       " 'optimal stopping',\n",
       " 'search theory',\n",
       " 'annals of statistics',\n",
       " 'operations research',\n",
       " 'katehakis m',\n",
       " 'sequential methods',\n",
       " 'sequential experiments',\n",
       " 'stochastic optimization',\n",
       " 'logic programming',\n",
       " 'information gain',\n",
       " 'data analysis',\n",
       " 'nonlinear dimensionality reduction',\n",
       " 'eigenvalue eigenvector',\n",
       " 'sequential nmf',\n",
       " 'methods of detecting exoplanets',\n",
       " 'circumstellar disks',\n",
       " 'kernel trick',\n",
       " 'kernel pca',\n",
       " 'locally linear embedding',\n",
       " 'local tangent space alignment',\n",
       " 'semidefinite programming',\n",
       " 'maximum variance unfolding',\n",
       " 'diffusion map',\n",
       " 't-distributed stochastic neighbor embedding',\n",
       " 'canonical correlation analysis',\n",
       " 'feature vectors',\n",
       " 'time series',\n",
       " 'locality sensitive hashing',\n",
       " 'random projection',\n",
       " 'maximally informative dimensions',\n",
       " 'semidefinite embedding',\n",
       " 'multifactor dimensionality reduction',\n",
       " 'semantic mapping',\n",
       " 'topological data analysis',\n",
       " 'sufficient dimension reduction',\n",
       " 'weighted correlation network analysis',\n",
       " 'hyperparameter optimization',\n",
       " 'cur matrix approximation',\n",
       " 'sammon mapping',\n",
       " 'johnsonlindenstrauss lemma',\n",
       " 'part of speech tagging',\n",
       " 'part of speech',\n",
       " 'bayesian network',\n",
       " 'linear dynamical system',\n",
       " 'sequence mining',\n",
       " 'probabilistic model',\n",
       " 'mixture distribution',\n",
       " 'compositional data',\n",
       " 'total size',\n",
       " 'hierarchical bayes model',\n",
       " 'hierarchical model',\n",
       " 'zipfs law',\n",
       " 'latent variable',\n",
       " 'bayesian setting',\n",
       " 'dirichlet distribution',\n",
       " 'conjugate prior',\n",
       " 'binomial distribution',\n",
       " 'multinomial distribution',\n",
       " 'negative binomial distribution',\n",
       " 'poisson distribution',\n",
       " 'exponential distribution',\n",
       " 'log-normal distribution',\n",
       " 'multivariate normal distribution',\n",
       " 'multivariate gaussian distribution',\n",
       " 'multivariate students-t distribution',\n",
       " 'multivariate t-distribution',\n",
       " 'posterior probability',\n",
       " 'expectation-maximization algorithm',\n",
       " 'em algorithm',\n",
       " 'k-means clustering',\n",
       " 'jump-diffusion model',\n",
       " 'financial economicschallenges',\n",
       " 'exponential growth',\n",
       " 'topic model',\n",
       " 'expectation maximization',\n",
       " 'excessive number of parameters',\n",
       " 'concentration parameter',\n",
       " 'circular error probable',\n",
       " 'dynamical consistency',\n",
       " 'financial derivatives',\n",
       " 'volatility smile',\n",
       " 'local volatility',\n",
       " 'image segmentation',\n",
       " 'minimum message length',\n",
       " 'iterative algorithm',\n",
       " 'expectation value',\n",
       " 'plug-in estimates',\n",
       " 'arithmetic mean',\n",
       " 'posterior sampling',\n",
       " 'gibbs sampling',\n",
       " 'method of moment matching',\n",
       " 'spectral method',\n",
       " 'real coordinate space',\n",
       " 'real space',\n",
       " 'logarithmically concave function',\n",
       " 'linear subspace',\n",
       " 'mathematical proof',\n",
       " 'heavy-tailed distribution',\n",
       " 'recent papers',\n",
       " 'links to papers',\n",
       " 'karl pearson',\n",
       " 'walter frank raphael weldon',\n",
       " 'mixture density',\n",
       " 'flexible mixture model',\n",
       " 'signal processing',\n",
       " 'latent variable models',\n",
       " 'spam filtering',\n",
       " 'spam or non-spam',\n",
       " 'explanatory variables',\n",
       " 'blood type',\n",
       " 'ordinal data',\n",
       " 'blood pressure',\n",
       " 'similarity function',\n",
       " 'independent variable',\n",
       " 'community ecology',\n",
       " 'parse tree',\n",
       " 'syntactic structure',\n",
       " 'probabilistic classification',\n",
       " 'ronald fisher',\n",
       " 'fisher ra',\n",
       " 'fishers linear discriminant',\n",
       " 'rao cr',\n",
       " 'anderson tw',\n",
       " 'mahalanobis distance',\n",
       " 'markov chain monte carlo',\n",
       " 'class membership probabilities',\n",
       " 'group membership probabilities',\n",
       " 'multiclass classification',\n",
       " 'statistically independent',\n",
       " 'binary data',\n",
       " 'linear combination',\n",
       " 'dot product',\n",
       " 'linear predictor function',\n",
       " 'discrete choice',\n",
       " 'multinomial logistic regression',\n",
       " 'probit regression',\n",
       " 'quadratic classifier',\n",
       " 'kernel estimation',\n",
       " 'k-nearest neighbor',\n",
       " 'decision tree learning',\n",
       " 'learning vector quantization',\n",
       " 'no-free-lunch theorem',\n",
       " 'uncertainty coefficient',\n",
       " 'medical imaging',\n",
       " 'video tracking',\n",
       " 'drug discovery',\n",
       " 'drug development',\n",
       " 'quantitative structure-activity relationship',\n",
       " 'speech recognition',\n",
       " 'handwriting recognition',\n",
       " 'biological classification',\n",
       " 'statistical natural language processing',\n",
       " 'document classification',\n",
       " 'search engines',\n",
       " 'credit scoring',\n",
       " 'compound term processing',\n",
       " 'data warehouse',\n",
       " 'deep learning',\n",
       " 'university of california berkeley',\n",
       " 'electrical engineering',\n",
       " 'andrew ng',\n",
       " 'aerobatic maneuver',\n",
       " 'robot software',\n",
       " 'humanmachine system',\n",
       " 'human operator',\n",
       " 'stefan schaal',\n",
       " 'pendulum swingup task',\n",
       " 'optimal control',\n",
       " 'brute-force search',\n",
       " 'brute-force solver',\n",
       " 'spline animation',\n",
       " 'pid control',\n",
       " 'inverse reinforcement learning',\n",
       " 'class of concepts',\n",
       " 'qualitative property',\n",
       " 'medical test',\n",
       " 'test method',\n",
       " 'quality control',\n",
       " 'gono go',\n",
       " 'result set',\n",
       " 'type i',\n",
       " 'type ii errors',\n",
       " 'types of errors',\n",
       " 'false positives',\n",
       " 'false negativesfalse positive error',\n",
       " 'false negativesfalse negative error',\n",
       " 'decision trees',\n",
       " 'random forests',\n",
       " 'probit model',\n",
       " 'the left',\n",
       " 'true positive rate',\n",
       " 'false negative rate',\n",
       " 'true negative rate',\n",
       " 'false positive rate',\n",
       " 'false discovery rate',\n",
       " 'negative predictive value',\n",
       " 'false omission rate',\n",
       " 'likelihood ratio',\n",
       " 'likelihood ratios',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Записываем полученные коллокации в файл**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(COLLOCS_FILE, \"w\") as f:\n",
    "    f.write('\\n'.join(collocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Статистика**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperlinks:\t9200\n",
      "filtered hl:\t11375\n",
      "collocations:\t3651\n"
     ]
    }
   ],
   "source": [
    "print(\"hyperlinks:\\t{}\".format(len(hyperlinks)))\n",
    "print(\"filtered hl:\\t{}\".format(len(filtered_hyperlinks)))\n",
    "print(\"collocations:\\t{}\".format(len(collocs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='documents_collect'></a>\n",
    "## Документы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обрабатываем текст с помощью [wikiextractor](https://github.com/attardi/wikiextractor). Получаем json файлы**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(WIKIEXTRACTOR_FOLDER + \"/WikiExtractor.py \" + \"--json \" + \"-o \" + WIKITEXTS_JSON_FOLDER + \" \" + WIKI_XML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Читаем их**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_str = \"\"\n",
    "for subdir in os.listdir(WIKITEXTS_JSON_FOLDER):\n",
    "    for file in os.listdir(WIKITEXTS_JSON_FOLDER + \"/\" + subdir):\n",
    "        with open(WIKITEXTS_JSON_FOLDER + subdir + \"/\" + file, \"r\") as f:\n",
    "            texts_str += f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "for text in texts_str.split('\\n'):\n",
    "    if text != '':  # in case of double \\n\n",
    "        texts.append(json.loads(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сохраняем полученные документы в коллекцию + миниобработка**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "    filename = text[\"title\"]\n",
    "    filename = re.sub(\"[^A-Za-zА-Яа-я0-9 ]\", \"\", filename)\n",
    "    filename = re.sub(\" +\", \"_\", filename)\n",
    "    article = '\\n'.join(text[\"text\"].split('\\n')[2:])  # remove name of article at the start\n",
    "    with open(WIKI_COLLECTION + filename + \".txt\", \"w\") as f:\n",
    "        f.write(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='syntaxnet'></a>\n",
    "# SyntaxNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='syntaxnet_run'></a>\n",
    "## Запуск SyntaxNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загружаем коллекцию, удаляем пунктуацию и переводим в нижний регистр. Получаем список предложений**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "for doc_id, filename in enumerate(os.listdir(WIKI_COLLECTION)):\n",
    "    with open(WIKI_COLLECTION + filename, \"r\") as f:\n",
    "        sentences_raw = f.read().split('.')\n",
    "    \n",
    "    for sentence in sentences_raw:\n",
    "        sentence_nopunct = re.sub(\"[^A-Za-zА-Яа-я ]\", '', sentence)\n",
    "        sentence_nopunct = sentence_nopunct.lower().strip()\n",
    "        if len(sentence_nopunct) > 1:\n",
    "            sentences.append(sentence_nopunct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запишем в файл каждое предложение в отдельной строке**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(SYNTAXNET_INPUT, \"w\") as f:\n",
    "    for sentence in sentences:\n",
    "        f.write(\"{}\\n\".format(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Прогоняем полученный файл через SyntaxNet** (docker взял [здесь](https://hub.docker.com/r/inemo/syntaxnet_eng/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! It took 508.83 s.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "if os.system(\"./run_syntaxnet.sh {} {}\".format(SYNTAXNET_INPUT, SYNTAXNET_OUTPUT)) != 0:\n",
    "    print(\"Something was wrong\")\n",
    "print(\"Done! It took {:.2f} s.\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выход syntaxnet'а"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "syntaxnet_out = pd.read_table(SYNTAXNET_OUTPUT, header=None,\n",
    "                              dtype={0: np.int, 6: np.int},\n",
    "                              quoting=csv.QUOTE_NONE, engine='c'\n",
    "                             )[[0, 1, 3, 6, 7]].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>2</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>machine</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>3</td>\n",
       "      <td>nmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>learning</td>\n",
       "      <td>VERB</td>\n",
       "      <td>10</td>\n",
       "      <td>csubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>6</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>kernel</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>6</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1     3   6         7\n",
       "0  1        in   ADP   2      case\n",
       "1  2   machine  NOUN   3      nmod\n",
       "2  3  learning  VERB  10     csubj\n",
       "3  4       the   DET   6       det\n",
       "4  5    kernel  NOUN   6  compound"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntaxnet_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "** !!! Это может пригодиться, но я пока это не использую **<br>\n",
    "[Пропустить](#label1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**К каждому слову добавим id предложения и его лемму**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "syntaxnet_out = pd.read_table(SYNTAXNET_OUTPUT, header=None,\n",
    "                              dtype={0: np.int, 6: np.int},\n",
    "                              quoting=csv.QUOTE_NONE, engine='c'\n",
    "                             )[[0, 1, 3, 6, 7]].fillna(\"\")\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "syntaxnet_out.columns = [[\"word_id\", \"word\", \"POS\",\n",
    "                          \"parent_id\", \"dependency\"]]\n",
    "\n",
    "syntaxnet_out[\"word_id\"] -= 1\n",
    "syntaxnet_out[\"parent_id\"] -= 1\n",
    "\n",
    "cur_sentence_id = -1\n",
    "sentence_ids = []\n",
    "lemmas = []\n",
    "\n",
    "for word_id, word, pos in zip(syntaxnet_out[\"word_id\"],\n",
    "                              syntaxnet_out[\"word\"],\n",
    "                              syntaxnet_out[\"POS\"]):\n",
    "    if word_id == 0:\n",
    "        cur_sentence_id += 1\n",
    "        \n",
    "    if pos == \"VERB\":\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "    elif pos == \"ADJ\":\n",
    "        lemma = lemmatizer.lemmatize(word, pos='a')\n",
    "    elif pos == \"ADV\":\n",
    "        lemma = lemmatizer.lemmatize(word, pos='r')\n",
    "    else:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='n')\n",
    "        \n",
    "    lemmas.append(lemma)\n",
    "    sentence_ids.append(cur_sentence_id)\n",
    "\n",
    "syntaxnet_out[\"sentence_id\"] = sentence_ids\n",
    "syntaxnet_out[\"lemma\"] = lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>dependency</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>1</td>\n",
       "      <td>case</td>\n",
       "      <td>0</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>machine</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>2</td>\n",
       "      <td>nmod</td>\n",
       "      <td>0</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>learning</td>\n",
       "      <td>VERB</td>\n",
       "      <td>9</td>\n",
       "      <td>csubj</td>\n",
       "      <td>0</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>5</td>\n",
       "      <td>det</td>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>kernel</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td>compound</td>\n",
       "      <td>0</td>\n",
       "      <td>kernel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_id      word   POS  parent_id dependency  sentence_id    lemma\n",
       "0        0        in   ADP          1       case            0       in\n",
       "1        1   machine  NOUN          2       nmod            0  machine\n",
       "2        2  learning  VERB          9      csubj            0    learn\n",
       "3        3       the   DET          5        det            0      the\n",
       "4        4    kernel  NOUN          5   compound            0   kernel"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntaxnet_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"label1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"syntaxnet_postprocess\"></a>\n",
    "## Обработка результатов SyntaxNet'а"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Открываем выход syntaxnet'а и составляем список деревьев**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(SYNTAXNET_OUTPUT, \"r\") as f:\n",
    "    syntaxnet_out = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# May be removed\n",
    "with open(SYNTAXNET_INPUT, \"r\") as f:\n",
    "    sentences = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_sentences = []\n",
    "sentence = []\n",
    "for line in syntaxnet_out.split(\"\\n\"):\n",
    "    if len(line) == 0:\n",
    "        processed_sentences.append(sentence)\n",
    "        sentence = []\n",
    "    else:\n",
    "        word = line.split(\"\\t\")\n",
    "        sentence.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deps = []\n",
    "for sentence in processed_sentences:\n",
    "    s = ''\n",
    "    for line in sentence:\n",
    "        s += \"\\t\".join(line) + '\\n'\n",
    "    deps.append(s)\n",
    "del deps[-1] # empty sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hsic can be extended to measure the dependence of multiple random variables\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Tree('extended', ['hsic', 'can', 'be', Tree('measure', ['to', Tree('dependence', ['the', Tree('variables', ['of', 'multiple', 'random'])])])])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "sent_dep = deps[50]\n",
    "graph = nltk.DependencyGraph(tree_str=sent_dep)\n",
    "tree = graph.tree()\n",
    "print(sentences[50])\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Выделим ветки деревьев **<br>\n",
    "Позже можно будет использовать другие признаки, например находятся ли слова в одном поддереве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_branches(tree):\n",
    "    def _get_branches(subtree, subbranches):\n",
    "        subbranches *= len(subtree)\n",
    "        for i, node in enumerate(subtree):\n",
    "            if isinstance(node, str):\n",
    "                subbranches[i] += (' ' + node)\n",
    "            if isinstance(node, nltk.tree.Tree):\n",
    "                subsubbranches = _get_branches(node, [subbranches[i] + ' ' + node.label()])\n",
    "                del subbranches[i]\n",
    "                subbranches[i:i] = subsubbranches\n",
    "        return subbranches\n",
    "    \n",
    "    branches = [t.label()]\n",
    "    return _get_branches(tree, branches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_branches = []\n",
    "for sent_dep in deps:\n",
    "    graph = nltk.DependencyGraph(tree_str=sent_dep)\n",
    "    tree = graph.tree()\n",
    "    syntax_branches += get_branches(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['extended generalization mapping the all features distributions of',\n",
       " 'extended generalization mapping the all features distributions arbitrary',\n",
       " 'extended generalization mapping individual',\n",
       " 'extended generalization mapping feature datapoint',\n",
       " 'extended generalization mapping done methods in']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntax_branches[40:45]\n",
    "\n",
    "# Example: feature datapoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
