in logic statistical inference and supervise learningtransduction or transductive inference is reason fromobserved specific training case to specific test case . in contrastinduction is reason from observe training casesto general rule which are then apply to the test case . the distinction ismost interesting in case where the prediction of the transductive model arenot achievable by any inductive model . note that this is cause by transductiveinference on different test set produce mutually inconsistent prediction . transduction wa introduce by vladimir vapnik in the s motivate byhis view that transduction be preferable to induction since accord to him induction requiressolving a more general problem infer a function before solve a morespecific problem compute output for new case when solve a problem ofinterest do not solve a more general problem a an intermediate step . try toget the answer that you really need but not a more general one . a similarobservation had been make earlier by bertrand russellwe shall reach the conclusion that socrates be mortal with a greater approach to certainty if we make our argument purely inductive than if we go by way of all men be mortal and then use deduction russell chap vii . an example of learn which be not inductive would be in the case of binaryclassification where the input tend to cluster in two group . a large set oftest input may help in find the cluster thus provide useful informationabout the classification label . the same prediction would not be obtainablefrom a model which induce a function base only on the training case . somepeople may call this an example of the closely relate semisupervised learn since vapniks motivation be quite different . an example of an algorithm in this category be the transductive support vector machine tsvm . a third possible motivation which lead to transduction arises through the needto approximate . if exact inference be computationally prohibitive one may atleast try to make sure that the approximation be good at the test input . inthis case the test input could come from an arbitrary distribution notnecessarily relate to the distribution of the training input which wouldntbe allow in semisupervised learn . an example of an algorithm falling inthis category be the bayesian committee machine bcm . the follow example problem contrast some of the unique property of transduction against induction . a collection of point is give such that some of the point are label a b or c but most of the point be unlabeled . the goal be to predict appropriate label for all of the unlabeled point . the inductive approach to solving this problem be to use the labeled point to train a supervise learn algorithm and then have it predict label for all of the unlabeled point . with this problem however the supervise learn algorithm will only have five label point to use a a basis for build a predictive model . it will certainly struggle to build a model that capture the structure of this data . for example if a nearestneighbor algorithm is use then the point near the middle will be label a or c even though it be apparent that they belong to the same cluster a the point labeled b . transduction have the advantage of be able to consider all of the point not just the labeled point while perform the labeling task . in this case transductive algorithm would label the unlabeled point accord to the cluster to which they naturally belong . the point in the middle therefore would most likely be label b because they are pack very close to that cluster . an advantage of transduction be that it may be able to make good prediction with few labeled point because it use the natural break find in the unlabeled point . one disadvantage of transduction be that it build no predictive model . if a previously unknown point is add to the set the entire transductive algorithm would need to be repeat with all of the point in order to predict a label . this can be computationally expensive if the data is make available incrementally in a stream . further this might cause the prediction of some of the old point to change which may be good or bad depending on the application . a supervise learn algorithm on the other hand can label new point instantly with very little computational cost . transduction algorithm can be broadly divide into two category those that seek to assign discrete label to unlabeled point and those that seek to regress continuous label for unlabeled point . algorithm that seek to predict discrete label tend to be derive by add partial supervision to a cluster algorithm . these can be far subdivide into two category those that cluster by partitioning and those that cluster by agglomerate . algorithm that seek to predict continuous label tend to be derive by add partial supervision to a manifold learn algorithm . partition transduction can be think of as topdown transduction . it be a semisupervised extension of partitionbased clustering . it be typically performed a followsof course any reasonable partitioning technique could be use with this algorithm . max flow min cut partitioning scheme be very popular for this purpose . agglomerative transduction can be think of a bottomup transduction . it be a semisupervised extension of agglomerative clustering . it is typically perform a followsmanifoldlearningbased transduction be still a very young field of research .