bayesian optimization be a sequential design strategy . for global optimization of blackbox function that doesnt require derivative . the term be generally attribute to jonas mockus and is coin in his work from a series of publication on global optimization in the s and s . since the objective function be unknown the bayesian strategy be to treat it a a random function and place a prior over it . the prior capture our belief about the behaviour of the function . after gather the function evaluation which are treat a data the prior is update . to form the posterior distribution over the objective function . the posterior distribution in turn is use to construct . an acquisition function often also refer to a infill sample criterion that determine what the next query point should be . example of acquisition function include probability of improvement . expect improvement bayesian expect loss upper confidence bound ucb thompson sampling . and mixture of these . they all tradeoff exploration and exploitation so as to minimize the number of function query . a such bayesian optimization is well suit for function that be very expensive to evaluate . the maximum of the acquisition function is typically find by resort to discretization or by mean of an auxiliary optimizer . the approach ha been apply to solve a wide range of problem include learn to rank interactive animation robotics sensor network automatic algorithm configuration automatic machine learning toolbox reinforcement learning planning visual attention architecture configuration in deep learn static program analysis experimental particle physic etc .