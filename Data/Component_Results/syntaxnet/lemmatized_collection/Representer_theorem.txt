in machine learn sequence labeling be a type of pattern recognition task that involve the algorithmic assignment of a categorical label to each member of a sequence of observed value . a common example of a sequence labeling task be part of speech tag which seek to assign a part of speech to each word in an input sentence or document . sequence labeling can be treat a a set of independent classification task one per member of the sequence . however accuracy is generally improve by make the optimal label for a give element dependent on the choice of nearby element use special algorithm to choose the globally best set of label for the entire sequence at once . a an example of why find the globally best label sequence might produce good result than label one item at a time consider the partofspeech tagging task just describe . frequently many word be member of multiple part of speech and the correct label of such a word can often be deduce from the correct label of the word to the immediate left or right . for example the word set can be either a noun or verb . in a phrase like he set the book down the word he be unambiguously a pronoun and the unambiguously a determiner and use either of these label set can be deduce to be a verb since noun very rarely follow pronoun and be less likely to precede determiner than verb be . but in other case only one of the adjacent word be similarly helpful . in he set and then knock over the table only the word he to the left be helpful cf . pick up the set and then knock over . conversely in . and also set the table only the word the to the right be helpful cf . and also set of book be . an algorithm that proceed from left to right label one word at a time can only use the tag of leftadjacent word and might fail in the second example above vice versa for an algorithm that proceed from right to left . most sequence labeling algorithm be probabilistic in nature relying on statistical inference to find the best sequence . the most common statistical model in use for sequence labeling make a markov assumption i . that the choice of label for a particular word be directly dependent only on the immediately adjacent label hence the set of label form a markov chain . this lead naturally to the hidden markov model hmm one of the most common statistical model use for sequence labeling . other common model in use be the maximum entropy markov model and conditional random field .