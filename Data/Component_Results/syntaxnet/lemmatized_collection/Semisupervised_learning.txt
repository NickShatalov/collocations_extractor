in machine learn the study and construction of algorithm that can learn from and make prediction on data be a common task . such algorithm work by make datadriven prediction or decision through build a mathematical model from input data . the data use to build the final model usually come from multiple datasets . in particular three data set are commonly use in different stage of the creation of the model . the model be initially fit on a training dataset that be a set of example use to fit the parameter e . weight of connection between neuron in artificial neural network of the model . the model e . a neural net or a naive bayes classifier is train on the training dataset use a supervise learn method e . gradient descent or stochastic gradient descent . in practice the training dataset often consist of pair of an input vector and the correspond answer vector or scalar which is commonly denote a the target . the current model be run with the training dataset and produce a result which is then compare with the target for each input vector in the training dataset . base on the result of the comparison and the specific learning algorithm being use the parameter of the model are adjust . the model fitting can include both variable selection and parameter estimation . successively the fitted model is use to predict the response for the observation in a second dataset call the validation dataset . the validation dataset provide an unbiased evaluation of a model fit on the training dataset while tune the model hyperparameters e . the number of hidden unit in a neural network . validation datasets can be use for regularization by early stop stop training when the error on the validation dataset increase a this be a sign of overfitting to the training dataset . this simple procedure is complicate in practice by the fact that the validation datasets error may fluctuate during training produce multiple local minimum . this complication ha lead to the creation of many adhoc rule for decide when overfitting ha truly begin . finally the test dataset be a dataset use to provide an unbiased evaluation of a final model fit on the training dataset . a training dataset be a dataset of example use for learn that be to fit the parameter e . weight of for example a classifier . most approach that search through training data for empirical relationship tend to overfit the data meaning that they can identify apparent relationship in the training data that do not hold in general . a test dataset be a dataset that be independent of the training dataset but that follow the same probability distribution a the training dataset . if a model fit to the training dataset also fit the test dataset well minimal overfitting ha take place see figure below . a good fitting of the training dataset a oppose to the test dataset usually point to overfitting . a test set be therefore a set of example use only to assess the performance i . generalization of a fully specified classifier . a validation dataset be a set of example use to tune the hyperparameters i . the architecture of a classifier . it be sometimes also call the development set or the dev set . in artificial neural network a hyperparameter be for example the number of hidden unit . it as well a the testing set a mention above should follow the same probability distribution a the training dataset . in order to avoid overfitting when any classification parameter need to be adjust it be necessary to have a validation dataset in addition to the training and test datasets . for example if the most suitable classifier for the problem is seek the training dataset is use to train the candidate algorithm the validation dataset is use to compare their performance and decide which one to take and finally the test dataset is use to obtain the performance characteristic such a accuracy sensitivity specificity fmeasure and so on . the validation dataset function a a hybrid it is train data use by test but neither a part of the lowlevel train nor a part of the final testing . the basic process of use a validation dataset for model selection a part of train dataset validation dataset and test dataset isan application of this process be in early stop where the candidate model be successive iteration of the same network and training stop when the error on the validation set grows choose the previous model the one with minimum error . most simply part of the training dataset can be set aside and use a a validation set this is know a the holdout method . common proportion be trainingvalidation . alternatively the hold out process can be repeat repeatedly partition the original training dataset into a training dataset and a validation dataset this is know a crossvalidation . these repeated partition can be do in various way such a divide into equal datasets and use them a trainingvalidation and then validationtraining or repeatedly select a random subset a a validation dataset . another example of parameter adjustment be hierarchical classification sometimes refer to a instance space decomposition which split a complete multiclass problem into a set of small classification problem . it serve for learn more accurate concept due to simple classification boundary in subtasks and individual feature selection procedure for subtasks . when do classification decomposition the central choice be the order of combination of small classification step call the classification path . depend on the application it can be derive from the confusion matrix and uncover the reason for typical error and finding ways to prevent the system make those in the future . for example on the validation set one can see which class are most frequently mutually confuse by the system and then the instance space decomposition is do a follow firstly the classification is do among well recognizable class and the difficult to separate class are treat a a single joint class and finally a a second classification step the joint class is classify into the two initially mutually confused class .