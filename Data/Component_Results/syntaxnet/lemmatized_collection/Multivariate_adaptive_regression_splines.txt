in statistic multivariate adaptive regression spline mar be a form of regression analysis introduce by jerome h . friedman in . it be a nonparametric regression technique . and can be see a an extension of linear model that automatically model nonlinearities and interaction between variable . the term mar is trademark and license to salford system . in order to avoid trademark infringements many open source implementation of mar are call earth . this section introduce mar use a few example . we start with a set of data a matrix of input variable x and a vector of the observed response y with a response for each row in x . for example the data could be . here there be only one independent variable so the x matrix be just a single column . give these measurement we would like to build a model which predict the expect y for a given x . a linear model for the above data be . the hat on the formula indicates that formula is estimate from the data . the figure on the right show a plot of this function . a line give the predict formula versus x with the original value of y show a red dot . the data at the extreme of x indicates that the relationship between y and x may be nonlinear look at the red dot relative to the regression line at low and high value of x . we thus turn to mar to automatically build a model taking into account nonlinearities . mar software construct a model from the give x and y a follow . the figure on the right show a plot of this function the predict formula versus x with the original value of y once again show a red dot . the predicted response be now a good fit to the original y value . mar ha automatically produce a kink . in the predict y to take into account nonlinearity . the kink is produce by hinge function . the hinge function be the expression start with formula . where formula . be formula if formula else formula . hinge function are describe in more detail below . in this simple example we can easily see from the plot that . y have a nonlinear relationship with x . and might perhaps guess that y varies with the square of x . however in general there will be multiple . independent variable . and the relationship between y and these variable will be unclear . and not easily visible by plot . we can use mar to discover that nonlinear relationship . an example mar expression with multiple variable be . this expression model air pollution the ozone level . a a function of the temperature and a few other variable . note that the last term in the formula on the last line . incorporates an interaction between formula . and formula . the figure on the right plot the predict . formula a formula and . formula vary . with the other variable fix at their median value . the figure show that wind doe not affect the ozone . level unless visibility be low . we see that mar can build quite flexible regression surface . by combine hinge function . to obtain the above expression the mar model building procedure . automatically selects which variables to use some variable be . important others not the position of the kink in the hinge . function and how the hinge function are combine . mar build model of the form . the model be a weight sum of basis function . formula . each formula be a constant coefficient . for example each line in the formula for ozone above be one basis function . multiply by it coefficient . each basis function . formula . take one of the follow three form . a constant . there be just one such term the intercept . in the ozone formula above the intercept term be . a hinge function . a hinge function have the form . formula . or . formula . mar automatically select variable . and value of those variable for knot of the hinge function . example of such basis function can be see . in the middle three line of the ozone formula . a product of two or more hinge function . these basis function can model interaction between two or more variable . an example be the last line of the ozone formula . hinge function be a key part of mar model . a hinge function take the form . or . where formula be a constant call the knot . the figure on the right show a mirrored pair of hinge function with a knot at . a hinge function be zero for part of it range so can be use to partition the data into disjoint region each of which can be treat independently . thus for example a mirrored pair of hinge function in the expression . create the piecewise linear graph shown for the simple mar model in the previous section . one might assume that only piecewise linear function can be form from hinge function but hinge function can be multiply together to form nonlinear function . hinge function are also call ramp hockey stick or rectifier function . instead of the formula notation use in this article hinge function are often represent by formula where formula mean take the positive part . mar build a model in two phase . the forward and the backward pas . this twostage approach be the same a that use by . recursive partitioning tree . mar start with a model which consist of just the intercept term . which be the mean of the response value . mar then repeatedly add basis function in pair to the model . at each step it find the pair of basis function that . give the maximum reduction in sumofsquares . residual error . it be a greedy algorithm . the two basis function in the pair . be identical except that a different . side of a mirror hinge function is use for each function . each new basis function consists of . a term already in the model . multiply by a new hinge function . a hinge function is define by a variable and a knot . so to add a new basis function mar must search over . all combination of the follow . exist term call parent term in this context . all variable to select one for the new basis function . all value of each variable for the knot of the new hinge function . to calculate the coefficient of each term . mar apply a linear regression over the term . this process of add term continues until . the change in residual error be too small to continue . or until the maximum number of term is reach . the maximum number of term . is specify by the user before model building start . the search at each step is do in a brute force fashion . but a key aspect of mar be that . because of the nature of hinge function . the search can be do relatively . quickly use a fast leastsquares update technique . actually the search be not quite brute force . the search can be speed up with a heuristic . that reduce the number . of parent term to consider at each step . fast mar . the forward pas usually build an overfit model . an overfit model have a good fit to the data use to build . the model but will not generalize well to new data . to build a model with good generalization ability . the backward pas prune the model . it remove term one by one . delete the least effective term at each step . until it find the best submodel . model subset are compare use the gcv criterion describe below . the backward pas have an advantage over the forward pas . at any step it can choose any term to delete . whereas the forward pas . at each step can only see the next pair of term . the forward pas add term in pair . but the backward pas typically discard one side of the pair . and so term are often not see in pair in the final model . a paired hinge can be see in . the equation for formula in the . first mar example above . there be no complete pair retain in the ozone example . the backward pas us generalize cross validation gcv to compare the performance of model subset in order to choose the best subset lower value of gcv be good . the gcv be a form of . regularization . it trade off goodnessoffit against model complexity . the formula for the gcv be . where r be the residual sumofsquares . measure on the training data and n be the . number of observation the number of row in the x matrix . the effectivenumberofparameters is define in . the mar context as . where penalty be about or the . mar software allow the user to preset penalty . note that . be the number of hingefunction knot . so the formula penalize the addition of knot . thus the gcv formula adjusts i . increase the training r to take into . account the flexibility of the model . we penalize flexibility because model that be too flexible will model the specific realization of noise in the data instead of just the systematic structure of the data . generalize cross validation is so name because . it use a formula to approximate the error . that would be determine by leaveoneout validation . it be just an approximation but work well in practice . gcvs were introduce by craven and . wahba and extend by friedman for mar . one constraint ha already been mention the user . can specify the maximum number of term in the forward pas . a further constraint can be place on the forward pas . by specify a maximum allowable degree of interaction . typically only one or two degree of interaction are allow . but high degree can be use when the data warrant it . the maximum degree of interaction in the first mar example . above be one i . no interaction or an additive model . in the ozone example it be two . other constraint on the forward pas be possible . for example the user can specify that interaction are allow . only for certain input variable . such constraint could make sense because of knowledge . of the process that generate the data . no regression modeling technique be best for all situation . the guideline below are intend to give an idea of the pro and con of mar . but there will be exception to the guideline . it be useful to compare mar to recursive partitioning and this is do below . recursive partitioning is also commonly call regression tree . decision tree or cart . see the recursive partitioning article for detail . several free and commercial software package be available for fit marstype model .