pattern recognition be a branch of machine learn that focus on the recognition of pattern and regularity in data although it be in some case consider to be nearly synonymous with machine learn . pattern recognition system be in many case train from label training data supervised learning but when no labeled data be available other algorithm can be use to discover previously unknown pattern unsupervised learn . the term pattern recognition machine learn data mining and knowledge discovery in database kdd be hard to separate a they largely overlap in their scope . machine learning be the common term for supervise learn method and originates from artificial intelligence whereas kdd and data mining have a large focus on unsupervised method and strong connection to business use . pattern recognition have it origin in engineer and the term be popular in the context of computer vision a lead computer vision conference is name conference on computer vision and pattern recognition . in pattern recognition there may be a high interest to formalize explain and visualize the pattern while machine learn traditionally focus on maximize the recognition rate . yet all of these domain have evolve substantially from their root in artificial intelligence engineering and statistic and theyve become increasingly similar by integrate development and idea from each other . in machine learning pattern recognition be the assignment of a label to a give input value . in statistic discriminant analysis wa introduce for this same purpose in . an example of pattern recognition be classification which attempt to assign each input value to one of a given set of class for example determine whether a give email be spam or nonspam . however pattern recognition be a more general problem that encompass other type of output as well . other example be regression which assign a realvalued output to each input sequence label which assign a class to each member of a sequence of value for example part of speech tag which assign a part of speech to each word in an input sentence and parsing which assign a parse tree to an input sentence describe the syntactic structure of the sentence . pattern recognition algorithms generally aim to provide a reasonable answer for all possible input and to perform most likely matching of the input take into account their statistical variation . this is oppose to pattern matching algorithm which look for exact match in the input with preexist pattern . a common example of a patternmatching algorithm be regular expression matching which look for pattern of a given sort in textual data and is include in the search capability of many text editor and word processor . in contrast to pattern recognition pattern matching be not generally a type of machine learning although patternmatching algorithms especially with fairly general carefully tailor pattern can sometimes succeed in provide similarquality output of the sort provide by patternrecognition algorithm . pattern recognition is generally categorize accord to the type of learn procedure use to generate the output value . supervise learn assumes that a set of train data the training set ha been provide consist of a set of instance that have be properly label by hand with the correct output . a learning procedure then generate a model that attempt to meet two sometimes conflict objective perform as well a possible on the training data and generalize as well a possible to new data usually this mean be a simple a possible for some technical definition of simple in accordance with occam razor discuss below . unsupervised learn on the other hand assumes train data that ha not be handlabeled and attempt to find inherent pattern in the data that can then be use to determine the correct output value for new data instance . a combination of the two that ha recently been explore be semisupervised learning which use a combination of label and unlabeled data typically a small set of label data combine with a large amount of unlabeled data . note that in case of unsupervised learn there may be no training data at all to speak of in other wordsand the data to be label be the training data . note that sometimes different term are use to describe the correspond supervised and unsupervised learning procedure for the same type of output . for example the unsupervised equivalent of classification be normally known a cluster base on the common perception of the task a involve no training data to speak of and of group the input data into cluster base on some inherent similarity measure e . the distance between instance consider a vector in a multidimensional vector space rather than assign each input instance into one of a set of predefined class . note also that in some field the terminology be different for example in community ecology the term classification is use to refer to what is commonly know a cluster . the piece of input data for which an output value is generate is formally term an instance . the instance is formally describe by a vector of feature which together constitute a description of all known characteristic of the instance . these feature vector can be see a define point in an appropriate multidimensional space and method for manipulate vector in vector space can be correspondingly apply to them such a compute the dot product or the angle between two vector . typically feature be either categorical also know a nominal i . consist of one of a set of unordered item such a a gender of male or female or a blood type of a b ab or o ordinal consisting of one of a set of order item e . large medium or small integervalued e . a count of the number of occurrence of a particular word in an email or realvalued e . a measurement of blood pressure . often categorical and ordinal data are group together likewise for integervalued and realvalued data . furthermore many algorithm work only in term of categorical data and require that realvalued or integervalued data be discretized into group e . less than between and or great than . many common pattern recognition algorithm be probabilistic in nature in that they use statistical inference to find the best label for a give instance . unlike other algorithm which simply output a best label often probabilistic algorithm also output a probability of the instance being describe by the give label . in addition many probabilistic algorithm output a list of the nbest label with associate probability for some value of n instead of simply a single best label . when the number of possible label be fairly small e . in the case of classification n may be set so that the probability of all possible label be output . probabilistic algorithm have many advantage over nonprobabilistic algorithm . feature selection algorithm attempt to directly prune out redundant or irrelevant feature . a general introduction to feature selection which summarize approach and challenge ha been give . the complexity of featureselection be because of it nonmonotonous character an optimization problem where give a total of formula feature the powerset consisting of all formula subset of feature need to be explore . the branchandbound algorithm doe reduce this complexity but be intractable for medium to large value of the number of available feature formula . for a largescale comparison of featureselection algorithm see . technique to transform the raw feature vectors feature extraction are sometimes use prior to application of the patternmatching algorithm . for example feature extraction algorithm attempt to reduce a largedimensionality feature vector into a smallerdimensionality vector that be easy to work with and encodes le redundancy use mathematical technique such a principal component analysis pca . the distinction between feature selection and feature extraction be that the result feature after feature extraction ha take place be of a different sort than the original feature and may not easily be interpretable while the feature leave after feature selection be simply a subset of the original feature . formally the problem of supervised pattern recognition can be state a follows give an unknown function formula the ground truth that map input instance formula to output label formula along with train data formula assumed to represent accurate example of the map produce a function formula that approximate as closely a possible the correct map formula . for example if the problem is filter spam then formula be some representation of an email and formula be either spam or nonspam . in order for this to be a welldefined problem approximates as closely a possible need to be define rigorously . in decision theory this is define by specify a loss function or cost function that assign a specific value to loss resulting from produce an incorrect label . the goal then be to minimize the expect loss with the expectation take over the probability distribution of formula . in practice neither the distribution of formula nor the ground truth function formula are know exactly but can be compute only empirically by collect a large number of sample of formula and handlabeling them use the correct value of formula a timeconsuming process which be typically the limiting factor in the amount of data of this sort that can be collect . the particular loss function depend on the type of label being predict . for example in the case of classification the simple zeroone loss function be often sufficient . this correspond simply to assign a loss of to any incorrect label and implies that the optimal classifier minimize the error rate on independent test data i . count up the fraction of instance that the learned function formula label wrongly which be equivalent to maximize the number of correctly classified instance . the goal of the learning procedure be then to minimize the error rate maximize the correctness on a typical test set . for a probabilistic pattern recognizer the problem be instead to estimate the probability of each possible output label give a particular input instance i . to estimate a function of the form . where the feature vector input be formula and the function f is typically parameterized by some parameter formula . in a discriminative approach to the problem f is estimate directly . in a generative approach however the inverse probability formula be instead estimated and combine with the prior probability formula use bayes rule a follows . when the label are continuously distribute e . in regression analysis the denominator involve integration rather than summation . the value of formula is typically learn using maximum a posteriori map estimation . this find the best value that simultaneously meet two conflicting object to perform as well a possible on the training data smallest errorrate and to find the simple possible model . essentially this combine maximum likelihood estimation with a regularization procedure that favor simple model over more complex model . in a bayesian context the regularization procedure can be view a place a prior probability formula on different value of formula . mathematically . where formula be the value use for formula in the subsequent evaluation procedure and formula the posterior probability of formula be give by . in the bayesian approach to this problem instead of choose a single parameter vector formula the probability of a give label for a new instance formula is compute by integrate over all possible value of formula weight accord to the posterior probability . the first pattern classifier the linear discriminant present by fisher be developed in the frequentist tradition . the frequentist approach entail that the model parameter are consider unknown but objective . the parameter are then compute estimate from the collected data . for the linear discriminant these parameter be precisely the mean vectors and the covariance matrix . also the probability of each class formula is estimate from the collected dataset . note that the usage of bayes rule in a pattern classifier doe not make the classification approach bayesian . bayesian statistic have it origin in greek philosophy where a distinction wa already make between the a priori and the a posteriori knowledge . later kant define his distinction between what be a priori known before observation and the empirical knowledge gain from observation . in a bayesian pattern classifier the class probability formula can be choose by the user which be then a priori . moreover experience quantify a a priori parameter value can be weight with empirical observation use e . the beta conjugate prior and dirichletdistributions . the bayesian approach facilitate a seamless intermixing between expert knowledge in the form of subjective probability and objective observation . probabilistic pattern classifier can be use accord to a frequentist or a bayesian approach . within medical science pattern recognition be the basis for computeraided diagnosis cad system . cad describe a procedure that support the doctor interpretation and finding . other typical application of pattern recognition technique be automatic speech recognition classification of text into several category e . spamnonspam email message the automatic recognition of handwritten postal code on postal envelope automatic recognition of image of human face or handwrite image extraction from medical form . the last two example form the subtopic image analysis of pattern recognition that deal with digital image a input to pattern recognition system . optical character recognition be a classic example of the application of a pattern classifier see . ocrexample . the method of sign one name wa capture with stylus and overlay start in . the stroke speed relative min relative max acceleration and pressure is use to uniquely identify and confirm identity . bank were first offer this technology but were content to collect from the fdic for any bank fraud and did not want to inconvenience customer . artificial neural network neural net classifier and deep learning have many realworld application in image process a few example . for a discussion of the aforementioned application of neural network in image process see e . in psychology pattern recognition making sense of and identify object be closely related to perception which explain how the sensory input human receive be made meaningful . pattern recognition can be think of in two different ways the first be template matching and the second be feature detection . a template be a pattern use to produce item of the same proportion . the templatematching hypothesis suggests that incoming stimuli are compare with template in the long term memory . if there be a match the stimulus is identify . feature detection model such a the pandemonium system for classify letter selfridge suggest that the stimuli are break down into their component part for identification . for example a capital e have three horizontal line and one vertical line . algorithm for pattern recognition depend on the type of label output on whether learn is supervise or unsupervised and on whether the algorithm be statistical or nonstatistical in nature . statistical algorithm can further be categorize a generative or discriminative . parametric . nonparametric . unsupervised . supervise . supervise . unsupervised . supervise . unsupervised .