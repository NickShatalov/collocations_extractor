in euclidean geometry linear separability be a property of a pair of set of point . this be most easily visualize in two dimension the euclidean plane by thinking of one set of point a being color blue and the other set of point a being color red . these two set be linearly separable if there exists at least one line in the plane with all of the blue point on one side of the line and all the red point on the other side . this idea immediately generalize to higherdimensional euclidean space if line is replace by hyperplane . the problem of determine if a pair of set be linearly separable and find a separating hyperplane if they be arises in several area . in statistic and machine learning classify certain type of data be a problem for which good algorithm exist that are base on this concept . let formula and formula be two set of point in an ndimensional euclidean space . then formula and formula be linearly separable if there exist n real number formula such that every point formula satisfy formula and every point formula satisfies formula where formula be the formulath component of formula . equivalently two set be linearly separable precisely when their respective convex hull be disjoint colloquially do not overlap . three noncollinear point in two class and be always linearly separable in two dimension . this is illustrate by the three example in the follow figure the all case be not shown but be similar to the all case . however not all set of four point no three collinear be linearly separable in two dimension . the following example would need two straight line and thus be not linearly separable . notice that three point which be collinear and of the form be also not linearly separable . a boolean function in n variable can be think of a an assignment of or to each vertex of a boolean hypercube in n dimension . this give a natural division of the vertex into two set . the boolean function is say to be linearly separable provide these two set of point be linearly separable . classifying data be a common task in machine learn . suppose some data point each belong to one of two set are give and we wish to create a model that will decide which set a new data point will be in . in the case of support vector machine a data point is view a a pdimensional vector a list of p number and we want to know whether we can separate such point with a pdimensional hyperplane . this is call a linear classifier . there be many hyperplanes that might classify separate the data . one reasonable choice a the best hyperplane be the one that represent the large separation or margin between the two set . so we choose the hyperplane so that the distance from it to the near data point on each side be maximized . if such a hyperplane exist it be known a the maximummargin hyperplane and the linear classifier it define is know a a maximum margin classifier . more formally give some training data formula a set of n point of the form . where the y be either or indicate the set to which the point formula belongs . each formula be a pdimensional real vector . we want to find the maximummargin hyperplane that divide the point have formula from those have formula . any hyperplane can be write a the set of point formula satisfy . where formula denote the dot product and formula the not necessarily normalize normal vector to the hyperplane . the parameter formula determine the offset of the hyperplane from the origin along the normal vector formula . if the training data be linearly separable we can select two hyperplanes in such a way that they separate the data and there be no point between them and then try to maximize their distance .