feature scaling be a method use to standardize the range of independent variable or feature of data . in data process it is also know a data normalization and is generally perform during the data preprocessing step . since the range of value of raw data varies widely in some machine learning algorithm objective function will not work properly without normalization . for example the majority of classifier calculate the distance between two point by the euclidean distance . if one of the feature have a broad range of value the distance will be govern by this particular feature . therefore the range of all feature should be normalize so that each feature contribute approximately proportionately to the final distance . another reason why feature scaling is apply be that gradient descent converge much faster with feature scale than without it . the simple method is rescale the range of feature to scale the range in or . select the target range depend on the nature of the data . the general formula be given a . formula . where formula be an original value formula be the normalized value . for example suppose that we have the student weight data and the student weight span pound pound . to rescale this data we first subtract from each student weight and divide the result by the difference between the maximum and minimum weight . formula . where formula be an original value formula be the normalized value . in machine learn we can handle various type of data e . audio signal and pixel value for image data and this data can include multiple dimension . feature standardization make the value of each feature in the data have zeromean when subtract the mean in the numerator and unitvariance . this method be widely use for normalization in many machine learn algorithm e . support vector machine logistic regression and artificial neural network . the general method of calculation be to determine the distribution mean and standard deviation for each feature . next we subtract the mean from each feature . then we divide the value mean is already subtract of each feature by it standard deviation . formula . where formula be the original feature vector formula be the mean of that feature vector and formula be it standard deviation . another option that is widely use in machinelearning be to scale the component of a feature vector such that the complete vector have length one . this usually mean divide each component by the euclidean length of the vector . in some application e . histogram feature it can be more practical to use the l norm i . manhattan distance cityblock length or taxicab geometry of the feature vector . this be especially important if in the follow learn step the scalar metric is use a a distance measure . in stochastic gradient descent feature scaling can sometimes improve the convergence speed of the algorithm . in support vector machine it can reduce the time to find support vector . note that feature scaling change the svm result .