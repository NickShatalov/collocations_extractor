catastrophic interference also known a catastrophic forgetting be the tendency of an artificial neural network to completely and abruptly forget previously learn information upon learn new information . neural network be an important part of the network approach and connectionist approach to cognitive science . these network use computer simulation to try to model human behaviour such a memory and learn . catastrophic interference be an important issue to consider when create connectionist model of memory . it wa originally bring to the attention of the scientific community by research from mccloskey and cohen and ractcliff . it be a radical manifestation of the sensitivitystability dilemma or the stabilityplasticity dilemma . specifically these problem refer to the issue of be able to make an artificial neural network that be sensitive to but not disrupt by new information . lookup table and connectionist network lie on the opposite side of the stability plasticity spectrum . the former remain completely stable in the presence of new information but lack the ability to generalize i . infer general principle from new input . on the other hand connectionist network like the standard backpropagation network be very sensitive to new information and can generalize on new input . backpropagation model can be consider good model of human memory insofar a they mirror the human ability to generalize but these network often exhibit le stability than human memory . notably these backpropagation network be susceptible to catastrophic interference . this is consider an issue when attempt to model human memory because unlike these network human typically do not show catastrophic forgetting . thus the issue of catastrophic interference must be eradicate from these backpropagation model in order to enhance the plausibility a model of human memory . the term catastrophic interference wa originally coin by mccloskey and cohen but wa also bring to the attention of the scientific community by research from ratcliff . mccloskey and cohe n note the problem of catastrophic interference during two different experiment with backpropagation neural network model . in their first experiment they train a standard backpropagation neural network on a single training set consisting of singledigit one problem i . through and through until the network could represent and respond properly to all of them . the error between the actual output and the desire output steadily decline across training session which reflect that the network learn to represent the target output good across trial . next they train the network on a single training set consisting of singledigit two problem i . through and through until the network could represent respond properly to all of them . they note that their procedure be similar to how a child would learn their addition fact . follow each learn trial on the two facts the network wa test for it knowledge on both the one and two addition fact . like the one facts the two fact were readily learn by the network . however mccloskey and cohen note the network be no longer able to properly answer the one addition problem even after one learn trial of the two addition problem . the output pattern produce in response to the one facts often resemble an output pattern for an incorrect number more closely than the output pattern for an incorrect number . this is consider to be a drastic amount of error . furthermore the problem and which were include in both training set even show dramatic disruption during the first learning trial of the two fact . in their second connectionist model mccloskey and cohen attempt to replicate the study on retroactive interference in human by barnes and underwood . they train the model on ab and ac list and use a context pattern in the input vector input pattern to differentiate between the list . specifically the network wa train to responds with the right b response when show the a stimulus and ab context pattern and to respond with the correct c response when show the a stimulus and the ac context pattern . when the model wa train concurrently on the ab and ac item then the network readily learn all of the association correctly . in sequential train the ab list wa train first follow by the ac list . after each presentation of the ac list performance wa measure for both the ab and ac list . they find that the amount of train on the ac list in barnes and underwood study that lead to correct response lead to nearly correct response by the backpropagation network . furthermore they find that the network tend to show response that look like the c response pattern when the network wa prompt to give the b response pattern . this indicate that the ac list apparently have overwrite the ab list . this could be liken to learn the word dog follow by learn the word stool and then find that you cannot recognize the word cat well but instead think of the word stool when present with the word dog . mccloskey and cohen try to reduce interference through a number of manipulation including change the number of hidden unit change the value of the learn rate parameter overtraining on the ab list freeze certain connection weight change target value and instead . and . however none of these manipulation satisfactorily reduce the catastrophic interference exhibit by the network . overall mccloskey and cohen conclude that . ratcliff use multiple set of backpropagation model apply to standard recognition memory procedure in which the item were sequentially learn . after inspect the recognition performance model he find two major problem . even one learn trial with new information result in a significant loss of the old information paralleling the finding of mccloskey and cohen . ratcliff also find that the resulting output be often a blend of the previous input and the new input . in large network item learn in group e . ab then cd be more resistant to forget than were item learn singly e . a then b then c . however the forget for item learn in group be still large . add new hidden units to the network did not reduce interference . this finding contradicts with study on human memory which indicate that discrimination increase with learn . ratcliff attempt to alleviate this problem by add response node that would selectively respond to old and new input . however this method did not work a these response node would become active for all input . a model which use a context pattern also fail to increase discrimination between new and old item . many researcher have suggest that the main cause of catastrophic interference be overlap in the representation at the hidden layer of distribute neural network . in a distributed representation any give input will tend to create change in the weight to many of the node . catastrophic forgetting occurs because when many of the weight where knowledge is store are change it be impossible for prior knowledge to be keep intact . during sequential learn the input become mix with the new input being superimpose over top of the old input . another way to conceptualize this is through visualize learn a movement through a weight space . this weight space can be liken to a spatial representation of all of the possible combination of weight that the network can possess . when a network first learns to represent a set of pattern it ha find a point in weight space which allow it to recognize all of the pattern that it ha see . however when the network learn a new set of pattern sequentially it will move to a place in the weight space that allow it to only recognize the new pattern . to recognize both set of pattern the network must find a place in weight space that can represent both the new and the old output . one way to do this be by connect a hidden unit to only a subset of the input unit . this reduce the likelihood that two different input will be encode by the same hidden unit and weight and so will decrease the chance of interference . indeed a number of the propose solution to catastrophic interference involve reduce the amount of overlap that occurs when store information in these weight . many of the early technique in reduce representational overlap involved make either the input vector or the hidden unit activation pattern orthogonal to one another . lewandowsky and li note that the interference between sequentially learn pattern is minimize if the input vector be orthogonal to each other . input vector are say to be orthogonal to each other if the pairwise product of their element across the two vector sum to zero . for example the pattern and are say to be orthogonal because . one of the technique which can create orthogonal representation at the hidden layer involve bipolar feature cod i . cod use and rather than and . orthogonal pattern tend to produce less interference with each other . however not all learning problem can be represent use these type of vector and some study report that the degree of interference be still problematic with orthogonal vector . simple technique such a vary the learn rate parameter in the backpropagation equation be not successful in reduce interference . vary the number of hidden node ha also been use to try and reduce interference . however the finding have been mix with some study finding that more hidden unit decrease interference and other study find it do not . below be a number of technique which have empirical support in successfully reduce catastrophic interference in backpropagation neural network . french propose that catastrophic interference arises in feedforward backpropagation network due to the interaction of node activation or activation overlap that occur in distribute representation at the hidden layer . specifically he define this activation overlap a the average share activation over all unit in the hidden layer calculate by sum the low activation of the node at the hidden layer and average this sum . for example if the activation at the hidden layer from one input be . and the activation from the next input are . the activation overlap would be . when use binary numberbinary representation of input row vectorvectors activation value will be through where indicate no activation overlap and indicate full activation overlap . french note that neural network which employ very localized representation do not show catastrophic interference because of the lack of overlap at the hidden layer . that be to say each input pattern will create a hidden layer representation that involve the activation of only one node so differ input will have an activation overlap of . thus he suggest that reduce the value of activation overlap at the hidden layer would reduce catastrophic interference in distributed network . specifically he propose that this could be do through change the distribute representation at the hidden layer to semidistributed representation . a semidistributed representation ha fewer hide node that be active andor a low activation value for these node for each representation which will make the representation of the different input overlap le at the hidden layer . french recommend that this could be do through activation sharpening a technique which slightly increase the activation of a certain number of the most active node in the hidden layer slightly reduce the activation of all the other unit and then change the inputtohidden layer weight to reflect these activation change similar to error backpropagation . overall the guideline for the process of activation sharpening are a follow . in his test of an inputhiddenoutput node backpropagation network where one node wa sharpened french find that this sharpening paradigm do result in one node be much more active than the other seven . moreover when sharpen this network take one fourth the time to relearn the initial input than a standard backpropagation without node sharpening . relearn be a measure of memory saving and thus extent of forget where more time to relearn suggests more forget ebbinghaus saving method . a twonode sharpened network perform even slightly well however if more than two node were sharpened forget increase again . accord to french the sharpened activation interfere le with weight in the network than unsharpened weight and this be due specifically to the way that backpropagation algorithm calculate weight change . activation near will change the weight of link less than activation near . consequently when there be many node with low activation due to sharpen the weight to and from these node will be modify much less than the weight on very active node . a a result when a new input is feed into the network sharpening will reduce activation overlap by limit the number of highly active hidden unit and will reduce the likelihood of representational overlap by reduce the number of weight that be to be change . thus node sharpening will decrease the amount of disruption in the old weight which store prior input pattern thereby reduce the likelihood of catastrophic forgetting . kortge propose a learn rule for train neural network call the novelty rule to help alleviate catastrophic interference . a it name suggest this rule help the neural network to learn only the component of a new input that differ from an old input . consequently the novelty rule change only the weight that were not previously dedicate to store information thereby reduce the overlap in representation at the hidden unit . thus even when input be somewhat similar to another dissimilar representation can be make at the hidden layer . in order to apply the novelty rule during learn the input pattern is replace by a novelty vector that represent the component that differ . the novelty vector for the first layer input unit to hidden unit is determine by take the target pattern away from the current output of the network the delta rule . for the second layer hidden unit to output unit the novelty vector be simply the activation of the hidden unit that result from use the novelty vector a an input through the first layer . weight change in the network are compute by use a modify delta rule with the novelty vector replace the activation value sum of the input . when the novelty rule is use in a standard backpropagation network there be no or lessen forgetting of old item when new item are present sequentially . however this rule can only apply to autoencoder or autoassociative network in which the target response for the output layer be identical to the input pattern . this be because the novelty vector would be meaningless if the desire output be not identical to the input a it would be impossible to calculate how much a new input differed from the old input . mcrae and hetherington argue that human unlike most neural network do not take on new learn task with a random set of weight . rather people tend to bring a wealth of prior knowledge to a task and this help to avoid the problem of interference . they propose that when a network is pretrained on a random sample of data prior to start a sequential learn task that this prior knowledge will naturally constrain how the new information can be incorporate . this would occur because a random sample of data from a domain which have a high degree of internal structure such a the english language training would capture the regularity or recur pattern find within that domain . since the domain is base on regularity a newly learn item will tend to be similar to the previously learn information which will allow the network to incorporate new data with little interference with exist data . specifically an input vector which follow the same pattern of regularity a the previously trained data should not cause a drastically different pattern of activation at the hidden layer or drastically alter weight . to test their hypothesis mcrae and hetherington compare the performance of a nave and pretrained autoencoder backpropagation network on three simulation of verbal learn task . the pretrained network wa train using letter base representation of english monosyllabic word or english word pair . all three task involve the learning of some consonantvowelconsonant cvc string or cvc pair list a follow by train on a second list of these item list b . afterwards the distribution of the hidden node activation were compare between the nave and pretrained network . in all three task the representation of a cvc in the nave network tend to be spread fairly evenly across all hidden node whereas most hidden node be inactive in the pretrained network . furthermore in the pretrained network the representational overlap between cvcs wa reduce compare to the nave network . the pretrained network also retain some similarity information a the representational overlap between similar cvcs like jep and zep be greater than for dissimilar cvcs such a jep and yug . this suggest that the pretrained network have a good ability to generalize i . notice the pattern than the nave network . most importantly this reduction in hidden unit activation and representational overlap result in significantly less forget in the pretrained network than the nave network essentially eliminate catastrophic interference . essentially the pretraining act to create internal orthogonalization of the activation at the hidden layer which reduce interference . thus pretraining be a simple way to reduce catastrophic forgetting in standard backpropagation network . french propose the idea of a pseudorecurrent backpropagation network in order to help reduce catastrophic interference see figure . in this model the network is separate into two functionally distinct but interact subnetworks . this model is biologically inspire and is base on research from mcclelland mcnaughton and oreilly . in this research mcclelland et al . suggest that the hippocampus and neocortex act a separable but complementary memory system . specifically the hippocampus short term memory storage and act gradually over time to transfer memory into the neocortex for long term memory storage . they suggest that the information that is store can be bring back to the hippocampus during active rehearsal reminiscence and sleep and renew activation be what act to transfer the information to the neocortex over time . in the pseudorecurrent network one of the subnetworks act a an early process area akin to the hippocampus and function to learn new input patter . the other subnetwork act a a finalstorage area akin to the neocortex . however unlike in mcclelland et al . model the finalstorage area send internally generate representation back to the early process area . this create a recurrent network . french propose that this interleaving of old representation with new representation be the only way to reduce radical forgetting . since the brain would most likely not have access to the original input pattern the pattern that would be feed back to the neocortex would be internally generate representation call pseudopatterns . these pseudopatterns be approximation of previous input and they can be interleave with the learning of new input . the use of these pseudopatterns could be biologically plausible a parallel between the consolidation of learn that occurs during sleep and the use of interleaved pseudopatterns . specifically they both serve to integrate new information with old information without disruption of the old information . when give an input and a teacher value is feed into the pseudorecurrent network would act a follows . when test on sequential learning of real world pattern categorization of edible and poisonous mushroom the pseudorecurrent network wa show le interference than a standard backpropagation network . this improvement be with both memory saving and exact recognition of old pattern . when the activation pattern of the pseudorecurrent network were investigate it wa show that this network automatically form semidistributed representation . since these type of representation involve fewer node being activate for each pattern it be likely what helped to reduce interference . not only do the pseudorecurrent model show reduce interference but also it model listlength and liststrength effect see in human . the listlength effect mean that add new item to a list harm the memory of early item . like human the pseudo recurrent network show a more gradual forget when to be train list be lengthened . the liststrength effect mean that when the strength of recognition for one item is increase there be no effect on the recognition of the other list item . this be an important finding a other model often exhibit a decrease in the recognition of other list item when one list item is strengthen . since the direct copying of weight from the early process area to the final storage area doe not seem highly biologically plausible the transfer of information to the final storage area can be do through train the final storage area with pseudopatterns create by the early processing area . however a disadvantage of the pseudorecurrent model be that the number of hide unit in the early process and final storage subnetworks must be identical . follow the same basic idea contribute by robin an and rousset have also propose a twonetwork artificial neural architecture with memory selfrefreshing that overcomes catastrophic interference when sequential learning task are carry out in distribute network train by backpropagation . the principle be to interleave at the time when new external pattern are learn those tobelearned new external pattern with internally generate pseudopatterns or pseudomemories that reflect the previously learn information . what mainly distinguish this model from those that use classical pseudorehearsal in feedforward multilayer network be a reverberating process that is use for generate pseudopatterns . this process which after a number of activity reinjections from a single random seed tend to go up to nonlinear network attractor be more suitable for optimally capture the deep structure of previously learn knowledge than a single feedforward pas of random activation . an and rousset have show that the learn mechanism they propose avoiding catastrophic forgetting provides a more appropriate way to deal with knowledge transfer a measure by learn speed ability to generalize and vulnerability to network damage . musca rousset and an have also show that pseudopatterns originate from an artificial reverberating neural network could induce familiarity in human with never see item in the way predict by simulation conduct with a twonetwork artificial neural architecture . furthermore an ha implement a version of the selfrefreshing mechanism use only one network train by the contrastive hebbian learn rule a train rule consider a more realistic than the largely use backpropagation algorithm but fortunately equivalent to the latter . so far the different solution to catastrophic interference that have been present concern task of sequential learning involving only nontemporally ordered list of item . but to be credible the selfrefreshing mechanism for static learn have to encompass our human ability to learn serially many temporal sequence of pattern without catastrophic interference e . learn one song follow by learn a second song without forget the first one . this wa do by ans rousset french and musca who have present in addition to simulation work an experiment that evidence a close similarity between the behaviour of human and the behaviour of the propose neuromimetic architecture . latent learning be a technique use by gutstein stump both to mitigate catastrophic interference and to take advantage of transfer learn . rather than manipulate the representation for new class use by the hidden node this approach try to train optimal representation for new class into the output node . it choose output encoding that be least likely to catastrophically interfere with exist response . give a net that ha learn to discriminate among one set of class use error correct output code ecoc a oppose to hot code optimal encoding for new class are choose by observe the net average responses to them . since these average responses arose while learn the original set of class without any exposure to the new class they are refer to as latently learn encoding . this terminology borrow from the concept of latent learn a introduce by tolman in . in effect this technique use transfer learn to avoid catastrophic interference by make a net responses to new class as consistent a possible with exist response to class already learn . kirkpatrick et al . demonstrate a method to train a single artificial neural network on multiple task use a technique call elastic weight consolidation . practopoietic theory proposes that biological system solve the problem of catastrophic interference by store longterm memory only in a general form not applicable to a give situation but instead loosely applicable to a class of different situation . in order to adjust the loosely applicable knowledge to the give current situation the process of anapoiesis is apply . anapoiesis stand for reconstruction of knowledgetransforming knowledge from a general form to a specific one . practopoietic theory is found in the theorem of cybernetics and is concern with the question of how cybernetic system obtain their capability to control and act .