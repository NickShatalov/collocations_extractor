in logic statistical inference and supervise learn . transduction or transductive inference is reason from . observe specific training case to specific test case . in contrast . induction is reason from observe training case . to general rule which are then apply to the test case . the distinction be . most interesting in case where the prediction of the transductive model are . not achievable by any inductive model . note that this is cause by transductive . inference on different test set produce mutually inconsistent prediction . transduction wa introduce by vladimir vapnik in the s motivate by . his view that transduction be preferable to induction since accord to him induction requires . solving a more general problem infer a function before solve a more . specific problem compute output for new case when solve a problem of . interest do not solve a more general problem a an intermediate step . try to . get the answer that you really need but not a more general one . a similar . observation had been make earlier by bertrand russell . we shall reach the conclusion that socrates be mortal with a greater approach to . certainty if we make our argument purely inductive than if we go by way of all men be mortal and then use . deduction russell chap vii . an example of learn which be not inductive would be in the case of binary . classification where the input tend to cluster in two group . a large set of . test input may help in find the cluster thus provide useful information . about the classification label . the same prediction would not be obtainable . from a model which induce a function base only on the training case . some . people may call this an example of the closely relate semisupervised learn since vapniks motivation be quite different . an example of an algorithm in this category be the transductive support vector machine tsvm . a third possible motivation which lead to transduction arises through the need . to approximate . if exact inference be computationally prohibitive one may at . least try to make sure that the approximation be good at the test input . in . this case the test input could come from an arbitrary distribution not . necessarily related to the distribution of the training input which wouldnt . be allow in semisupervised learn . an example of an algorithm fall in . this category be the bayesian committee machine bcm . the follow example problem contrast some of the unique property of transduction against induction . a collection of point is give such that some of the point are label a b or c but most of the point be unlabeled . the goal be to predict appropriate label for all of the unlabeled point . the inductive approach to solving this problem be to use the labeled point to train a supervise learn algorithm and then have it predict label for all of the unlabeled point . with this problem however the supervise learn algorithm will only have five label point to use a a basis for build a predictive model . it will certainly struggle to build a model that capture the structure of this data . for example if a nearestneighbor algorithm is use then the point near the middle will be label a or c even though it be apparent that they belong to the same cluster a the point labeled b . transduction have the advantage of be able to consider all of the point not just the labeled point while perform the labeling task . in this case transductive algorithm would label the unlabeled point accord to the cluster to which they naturally belong . the point in the middle therefore would most likely be label b because they are pack very close to that cluster . an advantage of transduction be that it may be able to make good prediction with few labeled point because it use the natural break find in the unlabeled point . one disadvantage of transduction be that it build no predictive model . if a previously unknown point is add to the set the entire transductive algorithm would need to be repeat with all of the point in order to predict a label . this can be computationally expensive if the data is make available incrementally in a stream . further this might cause the prediction of some of the old point to change which may be good or bad depending on the application . a supervise learn algorithm on the other hand can label new point instantly with very little computational cost . transduction algorithm can be broadly divide into two category those that seek to assign discrete label to unlabeled point and those that seek to regress continuous label for unlabeled point . algorithm that seek to predict discrete label tend to be derive by add partial supervision to a cluster algorithm . these can be far subdivide into two category those that cluster by partitioning and those that cluster by agglomerate . algorithm that seek to predict continuous label tend to be derive by add partial supervision to a manifold learn algorithm . partition transduction can be think of as topdown transduction . it be a semisupervised extension of partitionbased clustering . it be typically performed a follows . of course any reasonable partitioning technique could be use with this algorithm . max flow min cut partitioning scheme be very popular for this purpose . agglomerative transduction can be think of a bottomup transduction . it be a semisupervised extension of agglomerative clustering . it be typically performed a follows . manifoldlearningbased transduction be still a very young field of research .