the bagofwords model be a simplifying representation use in natural language process and information retrieval ir . also know a the vector space model . in this model a text such a a sentence or a document is represent a the bag multiset of it word disregard grammar and even word order but keep multiplicity . the bagofwords model ha also been use for computer vision . the bagofwords model is commonly use in method of document classification where the frequency of occurrence of each word is use a a feature for train a classifier . an early reference to bag of word in a linguistic context can be find in zellig harris article on distributional structure . the follow model a text document use bagofwords . here be two simple text document john like to watch movie . mary like movie too . john also like to watch football game . base on these two text document a list constructed a follow for each documentjohnlikestowatchmoviesmarylikesmoviestoojohnalsolikestowatchfootballgamesrepresenting each bagofwords a a json object and attribute to the respective javascript variablebow johnlikestowatchmoviesmarytoobow johnalsolikestowatchfootballgameseach key be the word and each value be the number of occurrence of that word in the give text document . the order of element be free so for example codice be also bow . it be also what we expect from a strict json object representation . note if another document be like a union of these two john like to watch movie . mary like movie too . john also like to watch football game . it javascript representation will bebow johnlikestowatchmoviesmarytooalsofootballgamesso a we see in the bag algebra the union of two document in the bagsofwords representation be formally the disjoint union sum the multiplicity of each element . formula . in practice the bagofwords model be mainly use a a tool of feature generation . after transform the text into a bag of word we can calculate various measure to characterize the text . the most common type of characteristic or feature calculate from the bagofwords model be term frequency namely the number of time a term appears in the text . for the example above we can construct the follow two list to record the term frequency of all the distinct word each entry of the list refer to count of the correspond entry in the list this be also the histogram representation . for example in the first list which represents document the first two entry be . the first entry corresponds to the word john which be the first word in the list and it value be because john appears in the first document time . similarly the second entry corresponds to the word like which be the second word in the list and it value be because like appears in the first document time . this list or vector representation doe not preserve the order of the word in the original sentence which be just the main feature of the bagofwords model . this kind of representation have several successful application for example email filter . however term frequency are not necessarily the best representation for the text . common word like the a to be almost always the term with highest frequency in the text . thus have a high raw count doe not necessarily mean that the correspond word be more important . to address this problem one of the most popular way to normalize the term frequency be to weight a term by the inverse of document frequency or tfidf . additionally for the specific purpose of classification supervised alternative have be developed that take into account the class label of a document . lastly binary presenceabsence or weighting is use in place of frequency for some problem . for instance this option is implement in the weka machine learn software system . bagofword model be an orderless document representationonly the count of word mattered . for instance in the above example john like to watch movie . mary like movie too the bagofwords representation will not reveal the fact that a person name is always follow by the verb like in this text . a an alternative the ngram model can be use to store this spatial information within the text . apply to the same example above a bigram model will parse the text into follow unit and store the term frequency of each unit as before . conceptually we can view bagofword model a a special case of the ngram model with n . for n the model is name wshingling where w be equivalent to n denote the number of grouped word . see language model for a more detailed discussion . a common alternative to the use of dictionary be the hashing trick where word be directly map to index with a hashing function . by map word to index directly with a hash function no memory is require to store a dictionary . hash collision be typically dealt with by use freedup memory to increase the number of hash bucket . in practice hash greatly simplifies the implementation of bagofwords model and improve their scalability . in bayesian spam filter an email message is model a an unordered collection of word select from one of two probability distribution one represent spam and one represent legitimate email ham . imagine that there be two literal bag full of word . one bag is fill with word find in spam message and the other bag is fill with word find in legitimate email . while any give word be likely to be find somewhere in both bag the spam bag will contain spamrelated word such a stock viagra and buy much more frequently while the ham bag will contain more word related to the user friend or workplace . to classify an email message the bayesian spam filter assume that the message be a pile of word that ha been pour out randomly from one of the two bag and use bayesian probability to determine which bag it be more likely to be .